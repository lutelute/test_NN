#!/usr/bin/env python3
"""
Grokking Interactive Dashboard
Streamlit-based interactive analysis tool

Usage:
    streamlit run interactive_dashboard.py
"""

import streamlit as st
import torch
import numpy as np
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import json
import os
import glob
from pathlib import Path

from model import ModularAdditionTransformer
from analyze import FourierAnalyzer


st.set_page_config(
    page_title="Grokking Analysis Dashboard",
    page_icon="ğŸ§ ",
    layout="wide",
    initial_sidebar_state="expanded"
)


@st.cache_resource
def load_model(checkpoint_path: str):
    """ãƒ¢ãƒ‡ãƒ«ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦ãƒ­ãƒ¼ãƒ‰"""
    checkpoint = torch.load(checkpoint_path, map_location="cpu", weights_only=False)

    # configã‚’checkpointå†…ã¾ãŸã¯åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å–å¾—
    if "config" in checkpoint:
        config = checkpoint["config"]
    else:
        # config.jsonã‹ã‚‰èª­ã¿è¾¼ã¿
        config_path = os.path.join(os.path.dirname(checkpoint_path), "config.json")
        if os.path.exists(config_path):
            with open(config_path, "r") as f:
                config = json.load(f)
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            config = {"p": 97, "d_model": 128, "n_heads": 4, "n_layers": 1, "n_tokens": 2}

    model = ModularAdditionTransformer(
        p=config["p"],
        d_model=config["d_model"],
        n_heads=config["n_heads"],
        n_layers=config["n_layers"],
        n_tokens=config.get("n_tokens", 2),
    )
    model.load_state_dict(checkpoint["model_state_dict"])
    model.eval()

    return model, config, checkpoint.get("epoch", 0)


@st.cache_data
def load_history(history_path: str):
    """å­¦ç¿’å±¥æ­´ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦ãƒ­ãƒ¼ãƒ‰"""
    with open(history_path, "r") as f:
        return json.load(f)


@st.cache_data
def load_fourier_history(fourier_path: str):
    """ãƒ•ãƒ¼ãƒªã‚¨å±¥æ­´ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦ãƒ­ãƒ¼ãƒ‰"""
    with open(fourier_path, "r") as f:
        return json.load(f)


def get_checkpoint_dirs():
    """åˆ©ç”¨å¯èƒ½ãªãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—"""
    dirs = []
    for d in os.listdir("."):
        if d.startswith("checkpoints") and os.path.isdir(d):
            # å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
            has_checkpoint = (
                os.path.exists(os.path.join(d, "best.pt")) or
                os.path.exists(os.path.join(d, "final.pt")) or
                any(f.startswith("checkpoint_epoch_") and f.endswith(".pt") for f in os.listdir(d))
            )
            if has_checkpoint:
                dirs.append(d)
    # modç•ªå·ã§ã‚½ãƒ¼ãƒˆï¼ˆcheckpoints_mod2, checkpoints_mod3, ...ï¼‰
    def sort_key(x):
        if "mod" in x:
            try:
                return (0, int(x.split("mod")[1].split("_")[0]))
            except:
                return (1, x)
        return (2, x)
    return sorted(dirs, key=sort_key)


def plot_training_curves(history):
    """å­¦ç¿’æ›²ç·šã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒƒãƒˆ"""
    fig = make_subplots(
        rows=1, cols=2,
        subplot_titles=("Accuracy", "Loss (log scale)"),
        horizontal_spacing=0.1
    )

    epochs = list(range(1, len(history["train_loss"]) + 1))
    train_acc = [a * 100 for a in history["train_acc"]]
    test_acc = [a * 100 for a in history["test_acc"]]

    # ç²¾åº¦
    fig.add_trace(
        go.Scatter(x=epochs, y=train_acc, name="Train Accuracy",
                  line=dict(color="#2196F3", width=2)),
        row=1, col=1
    )
    fig.add_trace(
        go.Scatter(x=epochs, y=test_acc, name="Test Accuracy",
                  line=dict(color="#F44336", width=2)),
        row=1, col=1
    )

    # Grokkingãƒã‚¤ãƒ³ãƒˆæ¤œå‡º
    grokking_epoch = None
    for i, (tr, te) in enumerate(zip(history["train_acc"], history["test_acc"])):
        if tr > 0.99 and te > 0.9:
            grokking_epoch = i + 1
            break

    if grokking_epoch:
        fig.add_vline(x=grokking_epoch, line_dash="dash", line_color="green",
                     annotation_text=f"Grokking @ {grokking_epoch}", row=1, col=1)

    # ãƒ­ã‚¹
    fig.add_trace(
        go.Scatter(x=epochs, y=history["train_loss"], name="Train Loss",
                  line=dict(color="#2196F3", width=2)),
        row=1, col=2
    )
    fig.add_trace(
        go.Scatter(x=epochs, y=history["test_loss"], name="Test Loss",
                  line=dict(color="#F44336", width=2)),
        row=1, col=2
    )

    fig.update_xaxes(title_text="Epoch", row=1, col=1)
    fig.update_xaxes(title_text="Epoch", row=1, col=2)
    fig.update_yaxes(title_text="Accuracy (%)", row=1, col=1, range=[0, 105])
    fig.update_yaxes(title_text="Loss", type="log", row=1, col=2)

    fig.update_layout(height=400, showlegend=True, legend=dict(orientation="h", y=-0.15))

    return fig


def plot_fourier_spectrum(analyzer):
    """ãƒ•ãƒ¼ãƒªã‚¨ã‚¹ãƒšã‚¯ãƒˆãƒ«ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒƒãƒˆ"""
    spectrum = analyzer.compute_fourier_spectrum()
    p = analyzer.p
    half_p = p // 2 + 1
    dominant = analyzer.find_dominant_frequencies(top_k=5)
    dominant_freqs = [f[0] for f in dominant]

    colors = ["#FF5722" if i in dominant_freqs else "#3F51B5" for i in range(half_p)]

    fig = go.Figure()
    fig.add_trace(go.Bar(
        x=list(range(half_p)),
        y=spectrum[:half_p].tolist(),
        marker_color=colors,
        text=[f"k={i}" if i in dominant_freqs else "" for i in range(half_p)],
        textposition="outside"
    ))

    fig.update_layout(
        title=f"Fourier Spectrum (p={p})",
        xaxis_title="Frequency k",
        yaxis_title="Power",
        height=400
    )

    return fig, dominant


def plot_embedding_circle(analyzer):
    """åŸ‹ã‚è¾¼ã¿ã®å††å‘¨æ§‹é€ ã‚’ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã«ãƒ—ãƒ­ãƒƒãƒˆ"""
    circular_result = analyzer.analyze_circular_structure()
    proj_2d = np.array(circular_result["projection_2d"])
    p = analyzer.p

    fig = go.Figure()

    # ç‚¹ã‚’ç·šã§çµã¶
    x_line = proj_2d[:, 0].tolist() + [proj_2d[0, 0]]
    y_line = proj_2d[:, 1].tolist() + [proj_2d[0, 1]]
    fig.add_trace(go.Scatter(
        x=x_line, y=y_line,
        mode="lines",
        line=dict(color="gray", width=0.5),
        showlegend=False
    ))

    # æ•£å¸ƒå›³
    fig.add_trace(go.Scatter(
        x=proj_2d[:, 0].tolist(),
        y=proj_2d[:, 1].tolist(),
        mode="markers",
        marker=dict(
            color=list(range(p)),
            colorscale="HSV",
            size=10,
            colorbar=dict(title="Token")
        ),
        text=[f"Token {i}" for i in range(p)],
        hovertemplate="Token %{text}<br>x: %{x:.3f}<br>y: %{y:.3f}<extra></extra>"
    ))

    fig.update_layout(
        title=f"Embedding Circular Structure<br>(Angle Correlation: {circular_result['angle_correlation']:.3f})",
        xaxis_title=f"Dimension {circular_result['top_2_dims'][0]}",
        yaxis_title=f"Dimension {circular_result['top_2_dims'][1]}",
        height=500,
        xaxis=dict(scaleanchor="y", scaleratio=1)
    )

    return fig, circular_result


def plot_fourier_basis_comparison(analyzer, dominant_freqs):
    """ãƒ•ãƒ¼ãƒªã‚¨åŸºåº•ã¨ã®æ¯”è¼ƒ"""
    if not dominant_freqs:
        return None

    k = dominant_freqs[0][0]
    p = analyzer.p
    n = np.arange(p)

    cos_theory = np.cos(2 * np.pi * k * n / p)
    sin_theory = np.sin(2 * np.pi * k * n / p)

    weights = analyzer.get_embedding_weights()
    best_dim = np.argmax(np.var(weights, axis=0))
    embed_dim = weights[:, best_dim]
    embed_norm = (embed_dim - embed_dim.mean()) / (embed_dim.std() + 1e-8)

    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=n.tolist(), y=cos_theory.tolist(),
        name=f"cos(2Ï€k{k}n/p)",
        line=dict(color="#2196F3", width=2)
    ))
    fig.add_trace(go.Scatter(
        x=n.tolist(), y=sin_theory.tolist(),
        name=f"sin(2Ï€k{k}n/p)",
        line=dict(color="#F44336", width=2)
    ))
    fig.add_trace(go.Scatter(
        x=n.tolist(), y=embed_norm.tolist(),
        name="Learned Embedding",
        line=dict(color="#4CAF50", width=2, dash="dash")
    ))

    fig.update_layout(
        title=f"Fourier Basis Comparison (k={k})",
        xaxis_title="Token n",
        yaxis_title="Normalized Value",
        height=400,
        legend=dict(orientation="h", y=-0.15)
    )

    return fig


def plot_fourier_evolution(fourier_history):
    """ãƒ•ãƒ¼ãƒªã‚¨ç›¸é–¢ã®æ™‚é–“ç™ºå±•"""
    epochs = fourier_history["epochs"]

    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=(
            "Fourier Correlation",
            "Angle Correlation",
            "Spectrum Concentration",
            "Circularity"
        )
    )

    fig.add_trace(go.Scatter(
        x=epochs, y=fourier_history["best_correlations"],
        line=dict(color="#9C27B0", width=2),
        fill="tozeroy", name="Fourier Corr"
    ), row=1, col=1)
    fig.add_hline(y=0.9, line_dash="dash", line_color="red", row=1, col=1)

    fig.add_trace(go.Scatter(
        x=epochs, y=fourier_history["angle_correlations"],
        line=dict(color="#00BCD4", width=2),
        fill="tozeroy", name="Angle Corr"
    ), row=1, col=2)
    fig.add_hline(y=0.9, line_dash="dash", line_color="red", row=1, col=2)

    fig.add_trace(go.Scatter(
        x=epochs, y=fourier_history["spectrum_concentrations"],
        line=dict(color="#FF5722", width=2),
        fill="tozeroy", name="Spectrum Conc"
    ), row=2, col=1)

    fig.add_trace(go.Scatter(
        x=epochs, y=fourier_history["circularities"],
        line=dict(color="#4CAF50", width=2),
        fill="tozeroy", name="Circularity"
    ), row=2, col=2)

    fig.update_layout(height=600, showlegend=False)
    fig.update_yaxes(range=[0, 1.05], row=1, col=1)
    fig.update_yaxes(range=[0, 1.05], row=1, col=2)

    return fig


def plot_neuron_correlation_matrix(model, config, grid_size=5, sample_size=500, fixed_dims=None):
    """
    ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³å‡ºåŠ›ã®ç›¸é–¢è¡Œåˆ—ï¼ˆæ•£å¸ƒå›³ã‚°ãƒªãƒƒãƒ‰ï¼‰- è»½é‡ç‰ˆ
    ç›¸é–¢.pngã®ã‚ˆã†ãªå¯è¦–åŒ–

    Args:
        fixed_dims: å›ºå®šã®æ¬¡å…ƒãƒªã‚¹ãƒˆï¼ˆæŒ‡å®šã™ã‚‹ã¨å…¨ã‚¨ãƒãƒƒã‚¯ã§åŒã˜æ¬¡å…ƒã‚’ä½¿ç”¨ï¼‰
    """
    p = config["p"]
    n_tokens = config.get("n_tokens", 3)

    # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦è»½é‡åŒ–
    if n_tokens == 2:
        all_inputs = [[a, b] for a in range(p) for b in range(p)]
    else:
        all_inputs = [[a, b, 0] for a in range(p) for b in range(p)]

    # ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆå†ç¾æ€§ã®ãŸã‚seedå›ºå®šï¼‰
    np.random.seed(42)
    if len(all_inputs) > sample_size:
        indices = np.random.choice(len(all_inputs), sample_size, replace=False)
        sampled_inputs = [all_inputs[i] for i in sorted(indices)]
    else:
        sampled_inputs = all_inputs

    with torch.no_grad():
        inputs = torch.tensor(sampled_inputs)
        _, intermediates = model.forward_with_intermediates(inputs)

    # pooledå±¤ã®å‡ºåŠ›ã‚’ä½¿ç”¨ï¼ˆshape: [batch, d_model]ï¼‰
    pooled = intermediates["pooled"].numpy()  # (batch, d_model)

    # å›ºå®šæ¬¡å…ƒãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚Œã°ãã‚Œã‚’ä½¿ç”¨ã€ãªã‘ã‚Œã°åˆ†æ•£ã§é¸æŠ
    if fixed_dims is not None:
        top_dims = fixed_dims[:grid_size]
    else:
        variances = np.var(pooled, axis=0)
        top_dims = np.argsort(variances)[::-1][:grid_size]

    # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
    fig = make_subplots(
        rows=grid_size, cols=grid_size,
        horizontal_spacing=0.02,
        vertical_spacing=0.02
    )

    # HSVã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—
    colors = [f"hsl({int(i * 360 / len(pooled))}, 70%, 50%)" for i in range(len(pooled))]

    for i in range(grid_size):
        for j in range(grid_size):
            dim_i = top_dims[i]
            dim_j = top_dims[j]

            x_data = pooled[:, dim_j]
            y_data = pooled[:, dim_i]

            # ç›¸é–¢ä¿‚æ•°ã‚’è¨ˆç®—
            corr = np.corrcoef(x_data, y_data)[0, 1] if i != j else 1.0

            fig.add_trace(
                go.Scatter(
                    x=x_data.tolist(),
                    y=y_data.tolist(),
                    mode="markers",
                    marker=dict(
                        color=list(range(len(pooled))),
                        colorscale="HSV",
                        size=3,
                        opacity=0.6
                    ),
                    showlegend=False,
                    hoverinfo="skip"
                ),
                row=i+1, col=j+1
            )

            # å¯¾è§’ç·šä¸Šã«ã¯æ¬¡å…ƒç•ªå·ã‚’è¡¨ç¤º
            if i == j:
                fig.add_annotation(
                    text=f"d{dim_i}",
                    xref=f"x{i*grid_size+j+1}" if i*grid_size+j > 0 else "x",
                    yref=f"y{i*grid_size+j+1}" if i*grid_size+j > 0 else "y",
                    x=0.5, y=0.5,
                    xanchor="center", yanchor="middle",
                    showarrow=False,
                    font=dict(color="yellow", size=10)
                )

    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèª¿æ•´
    fig.update_layout(
        height=600,
        width=600,
        title=f"Neuron Correlation Matrix (Top {grid_size} dims by variance)",
        plot_bgcolor="black",
        paper_bgcolor="black",
        font=dict(color="white"),
        showlegend=False
    )

    # è»¸ã®ç›®ç››ã‚Šã‚’éè¡¨ç¤º
    fig.update_xaxes(showticklabels=False, showgrid=False)
    fig.update_yaxes(showticklabels=False, showgrid=False)

    return fig


def get_epoch_path(checkpoint_dir, epoch):
    """ã‚¨ãƒãƒƒã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’å–å¾—ï¼ˆä¸¡æ–¹ã®å½¢å¼ã«å¯¾å¿œï¼‰"""
    # æ–°å½¢å¼: checkpoint_epoch_XXXXX.pt
    path1 = os.path.join(checkpoint_dir, f"checkpoint_epoch_{epoch:05d}.pt")
    if os.path.exists(path1):
        return path1
    # æ—§å½¢å¼: epoch_XXXXX.pt
    path2 = os.path.join(checkpoint_dir, f"epoch_{epoch}.pt")
    if os.path.exists(path2):
        return path2
    return None


def plot_epoch_progress(checkpoint_dir, selected_epoch, history, config):
    """ã‚¨ãƒãƒƒã‚¯é€²æ—ã®å¯è¦–åŒ–ï¼ˆåŸ‹ã‚è¾¼ã¿ç©ºé–“ + å­¦ç¿’æ›²ç·šï¼‰"""
    p = config["p"]

    # é¸æŠã•ã‚ŒãŸã‚¨ãƒãƒƒã‚¯ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
    epoch_path = get_epoch_path(checkpoint_dir, selected_epoch)
    if epoch_path is None:
        return None, None, None

    model, _, _ = load_model(epoch_path)
    analyzer = FourierAnalyzer(model)

    # åŸ‹ã‚è¾¼ã¿ã®å††å‘¨æ§‹é€ ã‚’å–å¾—
    circular_result = analyzer.analyze_circular_structure()
    proj_2d = np.array(circular_result["projection_2d"])

    # 2æ®µæ§‹æˆã®ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆã‚’ä½œæˆ
    fig = make_subplots(
        rows=2, cols=1,
        row_heights=[0.7, 0.3],
        subplot_titles=(
            f"Embedding Space (Epoch {selected_epoch}, Angle Corr: {circular_result['angle_correlation']:.3f})",
            "Training Progress"
        ),
        vertical_spacing=0.12
    )

    # ä¸Šæ®µ: åŸ‹ã‚è¾¼ã¿ç©ºé–“ã®æ•£å¸ƒå›³
    colors = [f"hsl({int(i * 360 / p)}, 80%, 50%)" for i in range(p)]
    fig.add_trace(
        go.Scatter(
            x=proj_2d[:, 0].tolist(),
            y=proj_2d[:, 1].tolist(),
            mode="markers",
            marker=dict(
                color=list(range(p)),
                colorscale="HSV",
                size=8,
                colorbar=dict(title="Token", x=1.02)
            ),
            text=[f"Token {i}" for i in range(p)],
            hovertemplate="Token %{text}<br>x: %{x:.3f}<br>y: %{y:.3f}<extra></extra>",
            showlegend=False
        ),
        row=1, col=1
    )

    # ç‚¹ã‚’ç·šã§çµã¶
    x_line = proj_2d[:, 0].tolist() + [proj_2d[0, 0]]
    y_line = proj_2d[:, 1].tolist() + [proj_2d[0, 1]]
    fig.add_trace(
        go.Scatter(
            x=x_line, y=y_line,
            mode="lines",
            line=dict(color="rgba(128,128,128,0.3)", width=1),
            showlegend=False
        ),
        row=1, col=1
    )

    # ä¸‹æ®µ: å­¦ç¿’æ›²ç·š
    epochs = list(range(1, len(history["train_acc"]) + 1))
    train_acc = [a * 100 for a in history["train_acc"]]
    test_acc = [a * 100 for a in history["test_acc"]]

    fig.add_trace(
        go.Scatter(x=epochs, y=train_acc, name="Train",
                   line=dict(color="#2196F3", width=2)),
        row=2, col=1
    )
    fig.add_trace(
        go.Scatter(x=epochs, y=test_acc, name="Test",
                   line=dict(color="#F44336", width=2)),
        row=2, col=1
    )

    # ç¾åœ¨ã®ã‚¨ãƒãƒƒã‚¯ä½ç½®ã‚’ç¸¦ç·šã§è¡¨ç¤º
    fig.add_vline(
        x=selected_epoch,
        line=dict(color="yellow", width=3, dash="solid"),
        row=2, col=1
    )

    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèª¿æ•´
    fig.update_xaxes(scaleanchor="y", scaleratio=1, row=1, col=1)
    fig.update_yaxes(title_text="Accuracy (%)", range=[0, 105], row=2, col=1)
    fig.update_xaxes(title_text="Epoch", row=2, col=1)

    fig.update_layout(
        height=700,
        showlegend=True,
        legend=dict(orientation="h", y=-0.05),
        plot_bgcolor="black",
        paper_bgcolor="black",
        font=dict(color="white")
    )

    # ä¸Šæ®µã®èƒŒæ™¯ã‚’é»’ã«
    fig.update_xaxes(showgrid=True, gridcolor="rgba(255,255,255,0.1)", row=1, col=1)
    fig.update_yaxes(showgrid=True, gridcolor="rgba(255,255,255,0.1)", row=1, col=1)
    fig.update_xaxes(showgrid=True, gridcolor="rgba(255,255,255,0.2)", row=2, col=1)
    fig.update_yaxes(showgrid=True, gridcolor="rgba(255,255,255,0.2)", row=2, col=1)

    # ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ç›¸é–¢è¡Œåˆ—ã‚‚ç”Ÿæˆï¼ˆè»½é‡ç‰ˆ: 5Ã—5, 500ã‚µãƒ³ãƒ—ãƒ«ï¼‰
    # fixed_dimsãŒæ¸¡ã•ã‚Œã¦ã„ã‚Œã°ä½¿ç”¨
    corr_fig = plot_neuron_correlation_matrix(model, config, grid_size=5, sample_size=500, fixed_dims=None)

    return fig, circular_result, corr_fig, model


def plot_mlp_output_matrix(model, config, use_logits=True):
    """MLPå‡ºåŠ›è¡Œåˆ—ã®å¯è¦–åŒ–ï¼ˆæ»‘ã‚‰ã‹ãªæ³¢é¢ç”¨ã«logitsã‚’ä½¿ç”¨ï¼‰"""
    p = config["p"]
    n_tokens = config.get("n_tokens", 2)

    if n_tokens == 2:
        # ãƒãƒƒãƒå‡¦ç†ã§é«˜é€ŸåŒ–
        all_inputs = torch.tensor([[a, b] for a in range(p) for b in range(p)])
        with torch.no_grad():
            all_logits = model(all_inputs)
        all_preds = all_logits.argmax(dim=-1).numpy().reshape(p, p)
        pred_matrix = all_preds

        # æ­£è§£ã‚¯ãƒ©ã‚¹ã®logitã‚’å–å¾—ï¼ˆæ»‘ã‚‰ã‹ãªæ³¢é¢ç”¨ï¼‰
        expected = np.array([[(a + b) % p for b in range(p)] for a in range(p)])
        correct_indices = expected.flatten()
        logit_matrix = all_logits[np.arange(p * p), correct_indices].numpy().reshape(p, p)

        xlabel, ylabel = "b", "a"
        title = "(a+b) mod p"
    else:
        # 3ãƒˆãƒ¼ã‚¯ãƒ³ãƒ¢ãƒ‡ãƒ«ç”¨ãƒãƒƒãƒå‡¦ç†
        all_inputs = torch.tensor([[a, 0, c] for a in range(p) for c in range(p)])
        with torch.no_grad():
            all_logits = model(all_inputs)
        all_preds = all_logits.argmax(dim=-1).numpy().reshape(p, p)
        pred_matrix = all_preds

        expected = np.array([[(a + c) % p for c in range(p)] for a in range(p)])
        correct_indices = expected.flatten()
        logit_matrix = all_logits[np.arange(p * p), correct_indices].numpy().reshape(p, p)

        xlabel, ylabel = "c", "a+b"
        title = "(a+b+c) mod p"

    accuracy = (pred_matrix == expected).mean() * 100

    # 2Dãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆäºˆæ¸¬å€¤ï¼‰
    fig = px.imshow(
        pred_matrix,
        color_continuous_scale="Viridis",
        labels=dict(x=xlabel, y=ylabel, color="Prediction"),
        title=f"MLP Output: {title} (Accuracy: {accuracy:.1f}%)"
    )
    fig.update_layout(height=500)

    return fig, accuracy, pred_matrix, logit_matrix


def plot_mlp_output_3d(logit_matrix, config, interpolation_factor=2):
    """MLPå‡ºåŠ›ã®3Dã‚µãƒ¼ãƒ•ã‚§ã‚¹ãƒ—ãƒ­ãƒƒãƒˆï¼ˆæ»‘ã‚‰ã‹ãªæ³¢å½¢è¡¨ç¤ºï¼‰"""
    from scipy.ndimage import zoom

    p = config["p"]

    # è£œé–“ã§æ»‘ã‚‰ã‹ã«ã™ã‚‹
    if interpolation_factor > 1:
        smooth_matrix = zoom(logit_matrix, interpolation_factor, order=3)
    else:
        smooth_matrix = logit_matrix

    # x, yåº§æ¨™ã‚‚è£œé–“ã«åˆã‚ã›ã‚‹
    new_size = smooth_matrix.shape[0]
    x = np.linspace(0, p-1, new_size)
    y = np.linspace(0, p-1, new_size)

    # 3Dã‚µãƒ¼ãƒ•ã‚§ã‚¹ãƒ—ãƒ­ãƒƒãƒˆ
    fig = go.Figure(data=[go.Surface(
        x=x,
        y=y,
        z=smooth_matrix,
        colorscale="Viridis",
        showscale=True,
        colorbar=dict(title="Logit (confidence)"),
        contours=dict(
            z=dict(show=True, usecolormap=True, highlightcolor="white", project_z=True)
        )
    )])

    fig.update_layout(
        title="3D Surface: Correct Class Logit (Wave Pattern)",
        scene=dict(
            xaxis_title="b",
            yaxis_title="a",
            zaxis_title="Logit",
            camera=dict(
                eye=dict(x=1.5, y=1.5, z=1.0)
            ),
            bgcolor="black"
        ),
        height=500,
        paper_bgcolor="black",
        font=dict(color="white")
    )

    return fig


def main():
    st.title("ğŸ§  Grokking Analysis Dashboard")
    st.markdown("---")

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.header("Settings")

        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆé¸æŠ
        checkpoint_dirs = get_checkpoint_dirs()
        if not checkpoint_dirs:
            st.error("No checkpoint directories found!")
            return

        # demo_5epã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«è¨­å®š
        default_index = 0
        for i, d in enumerate(checkpoint_dirs):
            if "demo_5ep" in d:
                default_index = i
                break

        selected_dir = st.selectbox(
            "Select Checkpoint Directory",
            checkpoint_dirs,
            index=default_index
        )

        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆbest.pt, final.pt, ã¾ãŸã¯æœ€æ–°ã®checkpoint_epoch_*.ptï¼‰
        best_path = os.path.join(selected_dir, "best.pt")
        final_path = os.path.join(selected_dir, "final.pt")

        # åˆ©ç”¨å¯èƒ½ãªãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—
        available_checkpoints = []
        if os.path.exists(best_path):
            available_checkpoints.append(("best.pt (best)", best_path))
        if os.path.exists(final_path):
            available_checkpoints.append(("final.pt", final_path))

        # epoch checkpointsã‚‚è¿½åŠ 
        epoch_files = sorted([f for f in os.listdir(selected_dir)
                             if f.startswith("checkpoint_epoch_") and f.endswith(".pt")])
        for ef in epoch_files:
            ep_num = ef.replace("checkpoint_epoch_", "").replace(".pt", "")
            available_checkpoints.append((f"epoch {int(ep_num)}", os.path.join(selected_dir, ef)))

        if not available_checkpoints:
            st.error("No checkpoint files found!")
            return

        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆé¸æŠï¼ˆè¤‡æ•°ã‚ã‚‹å ´åˆï¼‰
        if len(available_checkpoints) > 1:
            cp_names = [cp[0] for cp in available_checkpoints]
            selected_cp_idx = st.selectbox(
                "Select Checkpoint",
                range(len(cp_names)),
                format_func=lambda i: cp_names[i],
                index=len(cp_names) - 1  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯æœ€æ–°
            )
            checkpoint_path = available_checkpoints[selected_cp_idx][1]
        else:
            checkpoint_path = available_checkpoints[0][1]

        history_path = os.path.join(selected_dir, "history.json")
        fourier_path = os.path.join(selected_dir, "fourier_history.json")

        st.markdown("---")
        st.header("Model Info")

        # ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
        try:
            model, config, epoch = load_model(checkpoint_path)
            analyzer = FourierAnalyzer(model)

            st.success(f"âœ… Model loaded (epoch {epoch})")
            st.json({
                "p": config["p"],
                "n_tokens": config.get("n_tokens", 2),
                "d_model": config["d_model"],
                "n_heads": config["n_heads"],
                "n_layers": config["n_layers"]
            })
        except Exception as e:
            st.error(f"Failed to load model: {e}")
            return

    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8 = st.tabs([
        "ğŸ“ˆ Training Progress",
        "ğŸ”¬ Fourier Analysis",
        "â±ï¸ Evolution",
        "ğŸ¯ Model Output",
        "ğŸ¬ Epoch Slider",
        "ğŸ“ Fourier Theory",
        "ğŸ” Attention",
        "ğŸ§  Neurons"
    ])

    with tab1:
        st.header("ğŸ“ˆ Training Progress")

        # è§£èª¬
        with st.expander("ğŸ“š Grokkingã¨ã¯ï¼Ÿ", expanded=False):
            st.markdown("""
            **Grokkingï¼ˆã‚°ãƒ­ãƒƒã‚­ãƒ³ã‚°ï¼‰** ã¯ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãŒ**éå­¦ç¿’ã—ãŸå¾Œã«çªç„¶æ±åŒ–ã™ã‚‹**ç¾è±¡ã§ã™ã€‚

            ### å…¸å‹çš„ãªå­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³
            1. **Phase 1: è¨˜æ†¶ï¼ˆMemorizationï¼‰**
               - è¨“ç·´ç²¾åº¦ãŒæ€¥é€Ÿã«100%ã«åˆ°é”
               - ãƒ†ã‚¹ãƒˆç²¾åº¦ã¯ä½ã„ã¾ã¾ï¼ˆéå­¦ç¿’çŠ¶æ…‹ï¼‰
               - ãƒ¢ãƒ‡ãƒ«ã¯è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’ã€Œæš—è¨˜ã€ã—ã¦ã„ã‚‹

            2. **Phase 2: æ±åŒ–ï¼ˆGeneralizationï¼‰**
               - è¨“ç·´ç²¾åº¦ã¯100%ã®ã¾ã¾
               - çªç„¶ãƒ†ã‚¹ãƒˆç²¾åº¦ãŒæ€¥ä¸Šæ˜‡ â† **ã“ã‚ŒãŒGrokking!**
               - ãƒ¢ãƒ‡ãƒ«ãŒã€ŒçœŸã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã€ã‚’ç™ºè¦‹

            ### ãªãœèµ·ã“ã‚‹ï¼Ÿ
            - **Weight Decayï¼ˆé‡ã¿æ¸›è¡°ï¼‰** ãŒéµ
            - è¤‡é›‘ãªè¨˜æ†¶è§£ã¯å¾ã€…ã«ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’å—ã‘ã‚‹
            - ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ•ãƒ¼ãƒªã‚¨è§£ãŒæœ€çµ‚çš„ã«å‹åˆ©ã™ã‚‹

            ### ã“ã®ã‚°ãƒ©ãƒ•ã®è¦‹æ–¹
            - **é’ç·š**: è¨“ç·´ç²¾åº¦ï¼ˆæ—©æœŸã«100%åˆ°é”ï¼‰
            - **æ©™ç·š**: ãƒ†ã‚¹ãƒˆç²¾åº¦ï¼ˆé…ã‚Œã¦æ€¥ä¸Šæ˜‡ = Grokkingï¼‰
            - èµ¤ã„ç¸¦ç·š: Train/Testç²¾åº¦ã®å·®ãŒæœ€å¤§ã®ç‚¹ï¼ˆéå­¦ç¿’ãƒ”ãƒ¼ã‚¯ï¼‰
            """)

        if os.path.exists(history_path):
            history = load_history(history_path)

            col1, col2, col3, col4 = st.columns(4)
            with col1:
                final_train_acc = history["train_acc"][-1] * 100
                st.metric("Final Train Accuracy", f"{final_train_acc:.1f}%")
            with col2:
                final_test_acc = history["test_acc"][-1] * 100
                st.metric("Final Test Accuracy", f"{final_test_acc:.1f}%")
            with col3:
                final_train_loss = history["train_loss"][-1]
                st.metric("Final Train Loss", f"{final_train_loss:.4f}")
            with col4:
                total_epochs = len(history["train_loss"])
                st.metric("Total Epochs", total_epochs)

            fig = plot_training_curves(history)
            st.plotly_chart(fig, use_container_width=True)

            # Grokkingæ¤œå‡º
            train_acc = np.array(history["train_acc"])
            test_acc = np.array(history["test_acc"])
            gap = train_acc - test_acc
            max_gap_epoch = np.argmax(gap)
            if gap[max_gap_epoch] > 0.3:
                st.info(f"ğŸ¯ Grokkingæ¤œå‡º: ã‚¨ãƒãƒƒã‚¯{max_gap_epoch}ã§éå­¦ç¿’ãƒ”ãƒ¼ã‚¯ï¼ˆTrain-Testå·®={gap[max_gap_epoch]*100:.1f}%ï¼‰ã€ãã®å¾Œæ±åŒ–")
        else:
            st.warning("history.json not found")

    with tab2:
        st.header("ğŸ”¬ Fourier Analysis")

        # æ¦‚è¦è§£èª¬
        with st.expander("ğŸ“š ãƒ•ãƒ¼ãƒªã‚¨è§£æã¨ã¯ï¼Ÿ", expanded=False):
            st.markdown("""
            **ãƒ•ãƒ¼ãƒªã‚¨è§£æ** ã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ã—ãŸå†…éƒ¨è¡¨ç¾ã‚’å‘¨æ³¢æ•°æˆåˆ†ã«åˆ†è§£ã—ã¦åˆ†æã—ã¾ã™ã€‚

            ### ãªãœãƒ•ãƒ¼ãƒªã‚¨è¡¨ç¾ãŒé‡è¦ï¼Ÿ
            Grokkingã—ãŸãƒ¢ãƒ‡ãƒ«ã¯ã€å…¥åŠ›ã‚’**ãƒ•ãƒ¼ãƒªã‚¨åŸºåº•**ï¼ˆcos, sinæ³¢ï¼‰ã§è¡¨ç¾ã™ã‚‹ã“ã¨ã‚’å­¦ç¿’ã—ã¾ã™ã€‚

            ### è¦‹ã‚‹ã¹ããƒã‚¤ãƒ³ãƒˆ
            | ã‚°ãƒ©ãƒ• | æ„å‘³ | è‰¯ã„çŠ¶æ…‹ |
            |--------|------|----------|
            | **Fourier Spectrum** | åŸ‹ã‚è¾¼ã¿ã®å‘¨æ³¢æ•°æˆåˆ† | ç‰¹å®šã®kã«ãƒ”ãƒ¼ã‚¯ãŒç«‹ã¤ |
            | **Embedding Circle** | åŸ‹ã‚è¾¼ã¿ã®2Då°„å½± | ãã‚Œã„ãªå††å½¢ã«ãªã‚‹ |
            | **Dominant Frequencies** | æœ€ã‚‚å¼·ã„å‘¨æ³¢æ•° | k=1,2,3ãªã©ã®ä½å‘¨æ³¢ãŒå¼·ã„ |

            ### æŒ‡æ¨™ã®è§£é‡ˆ
            - **Fourier corr > 0.7**: ãƒ•ãƒ¼ãƒªã‚¨è¡¨ç¾ã‚’å­¦ç¿’æ¸ˆã¿
            - **Circular corr > 0.9**: å††ç’°æ§‹é€ ãŒå½¢æˆã•ã‚Œã¦ã„ã‚‹
            """)

        col1, col2 = st.columns(2)

        with col1:
            st.subheader("Fourier Spectrum")
            fig_spectrum, dominant = plot_fourier_spectrum(analyzer)
            st.plotly_chart(fig_spectrum, use_container_width=True)

            st.markdown("**Dominant Frequencies:**")
            for freq, power in dominant[:5]:
                st.markdown(f"- k={freq}: power={power:.4f}")

        with col2:
            st.subheader("Embedding Circle")
            fig_circle, circular_result = plot_embedding_circle(analyzer)
            st.plotly_chart(fig_circle, use_container_width=True)

            fourier_result = analyzer.verify_fourier_representation()
            is_fourier = "âœ…" if fourier_result["is_fourier_representation"] else "âŒ"
            is_circular = "âœ…" if circular_result["is_circular"] else "âŒ"

            st.markdown(f"""
            **Analysis Results:**
            - Fourier Representation: {is_fourier} (corr={fourier_result['best_correlation']:.3f})
            - Circular Structure: {is_circular} (corr={circular_result['angle_correlation']:.3f})
            """)

        st.markdown("---")

        # ãƒ•ãƒ¼ãƒªã‚¨å­¦ç¿’ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        st.subheader("Interactive Fourier Learning")

        # è§£èª¬ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        with st.expander("ğŸ“š Why Fourier Representation Can Express Addition", expanded=False):
            st.markdown(r"""
### The Key: Angle Addition Formula

Fourier basis functions (cos, sin) have a special property called the **angle addition formula**:

$$\cos\left(\frac{2\pi k(a+b)}{p}\right) = \cos\left(\frac{2\pi ka}{p}\right)\cos\left(\frac{2\pi kb}{p}\right) - \sin\left(\frac{2\pi ka}{p}\right)\sin\left(\frac{2\pi kb}{p}\right)$$

$$\sin\left(\frac{2\pi k(a+b)}{p}\right) = \sin\left(\frac{2\pi ka}{p}\right)\cos\left(\frac{2\pi kb}{p}\right) + \cos\left(\frac{2\pi ka}{p}\right)\sin\left(\frac{2\pi kb}{p}\right)$$

### How the Neural Network Uses This

| Layer | Role |
|-------|------|
| **Embedding** | Encode each token as Fourier components: $a \to [\cos(2\pi ka/p), \sin(2\pi ka/p), ...]$ |
| **MLP** | Compute products using angle addition formula (multiplication + addition) |
| **Output** | Decode from Fourier space back to answer $(a+b) \mod p$ |

### Why Circular Structure Emerges

All pairs $(a, b)$ with the same sum $s = (a+b) \mod p$ have the **same Fourier representation** in the MLP output.

For $p=59$, there are 59 possible sum values ($s=0,1,2,...,58$), each corresponding to a different angle $2\pi s/p$ on a circle.

### Concrete Example (p=5, k=1)

For $a=2, b=3$, answer is $(2+3) \mod 5 = 0$

**Embeddings:**
- $\cos(2\pi \cdot 2/5) \approx -0.81$, $\sin(2\pi \cdot 2/5) \approx 0.59$
- $\cos(2\pi \cdot 3/5) \approx -0.81$, $\sin(2\pi \cdot 3/5) \approx -0.59$

**Angle Addition:**
$$\cos(2\pi \cdot 5/5) = (-0.81)(-0.81) - (0.59)(-0.59) = 0.66 + 0.35 = 1.0 = \cos(0)$$

â†’ This represents sum = 0! âœ“

### Summary

**The angle addition formula transforms "addition" into "combination of multiplications"** â€” which MLPs can compute. This is why the network learns Fourier representations for modular arithmetic.
            """)

        p = config["p"]
        n = np.arange(p)
        weights = analyzer.get_embedding_weights()

        # åŠ æ³•å®šç†ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ‡ãƒ¢
        with st.expander("ğŸ§® Interactive Angle Addition Demo", expanded=False):
            st.markdown("**Try it yourself:** Select values of a, b, and k to see the angle addition formula in action.")

            col_demo1, col_demo2, col_demo3 = st.columns(3)
            with col_demo1:
                demo_a = st.slider("a", 0, max(1, p-1), min(2, p-1), key="demo_a")
            with col_demo2:
                demo_b = st.slider("b", 0, max(1, p-1), min(3, p-1), key="demo_b")
            with col_demo3:
                max_k = max(2, min(p//2, 10))  # æœ€ä½ã§ã‚‚2ã«ã™ã‚‹
                demo_k = st.slider("k (frequency)", 1, max_k, 1, key="demo_k")

            demo_sum = (demo_a + demo_b) % p

            # å€‹åˆ¥ã®cos/sinå€¤
            cos_a = np.cos(2 * np.pi * demo_k * demo_a / p)
            sin_a = np.sin(2 * np.pi * demo_k * demo_a / p)
            cos_b = np.cos(2 * np.pi * demo_k * demo_b / p)
            sin_b = np.sin(2 * np.pi * demo_k * demo_b / p)

            # åŠ æ³•å®šç†ã«ã‚ˆã‚‹è¨ˆç®—
            cos_sum_formula = cos_a * cos_b - sin_a * sin_b
            sin_sum_formula = sin_a * cos_b + cos_a * sin_b

            # ç›´æ¥è¨ˆç®—
            cos_sum_direct = np.cos(2 * np.pi * demo_k * demo_sum / p)
            sin_sum_direct = np.sin(2 * np.pi * demo_k * demo_sum / p)

            col_result1, col_result2 = st.columns(2)
            with col_result1:
                st.markdown(f"""
**Input Values:**
- $a = {demo_a}$, $b = {demo_b}$, $k = {demo_k}$
- $(a + b) \\mod {p} = {demo_sum}$

**Fourier Components of a:**
- $\\cos(2\\pi \\cdot {demo_k} \\cdot {demo_a}/{p}) = {cos_a:.4f}$
- $\\sin(2\\pi \\cdot {demo_k} \\cdot {demo_a}/{p}) = {sin_a:.4f}$

**Fourier Components of b:**
- $\\cos(2\\pi \\cdot {demo_k} \\cdot {demo_b}/{p}) = {cos_b:.4f}$
- $\\sin(2\\pi \\cdot {demo_k} \\cdot {demo_b}/{p}) = {sin_b:.4f}$
                """)
            with col_result2:
                st.markdown(f"""
**Angle Addition Formula:**
- $\\cos(a+b) = \\cos(a)\\cos(b) - \\sin(a)\\sin(b)$
- $= ({cos_a:.4f})({cos_b:.4f}) - ({sin_a:.4f})({sin_b:.4f})$
- $= {cos_sum_formula:.4f}$

**Direct Calculation:**
- $\\cos(2\\pi \\cdot {demo_k} \\cdot {demo_sum}/{p}) = {cos_sum_direct:.4f}$

**Match:** {"âœ… Yes!" if abs(cos_sum_formula - cos_sum_direct) < 1e-10 else "âŒ No"}
                """)

            # å††ä¸Šã§ã®å¯è¦–åŒ–
            fig_demo = go.Figure()

            # å˜ä½å††
            theta_circle = np.linspace(0, 2*np.pi, 100)
            fig_demo.add_trace(go.Scatter(
                x=np.cos(theta_circle).tolist(), y=np.sin(theta_circle).tolist(),
                mode="lines", line=dict(color="gray", width=1),
                name="Unit Circle", showlegend=False
            ))

            # å„ç‚¹ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
            fig_demo.add_trace(go.Scatter(
                x=[cos_a], y=[sin_a], mode="markers+text",
                marker=dict(size=15, color="#2196F3"),
                text=[f"a={demo_a}"], textposition="top right",
                name=f"a={demo_a}"
            ))
            fig_demo.add_trace(go.Scatter(
                x=[cos_b], y=[sin_b], mode="markers+text",
                marker=dict(size=15, color="#F44336"),
                text=[f"b={demo_b}"], textposition="top right",
                name=f"b={demo_b}"
            ))
            fig_demo.add_trace(go.Scatter(
                x=[cos_sum_direct], y=[sin_sum_direct], mode="markers+text",
                marker=dict(size=15, color="#4CAF50", symbol="star"),
                text=[f"sum={demo_sum}"], textposition="top right",
                name=f"(a+b) mod {p} = {demo_sum}"
            ))

            fig_demo.update_layout(
                title=f"Fourier Representation on Unit Circle (k={demo_k})",
                xaxis=dict(title="cos", range=[-1.5, 1.5], scaleanchor="y"),
                yaxis=dict(title="sin", range=[-1.5, 1.5]),
                height=400, width=400,
                plot_bgcolor="black", paper_bgcolor="black",
                font=dict(color="white")
            )
            st.plotly_chart(fig_demo, use_container_width=False)

        # å‘¨æ³¢æ•°é¸æŠ
        st.markdown("**Select frequencies to analyze (k values):**")
        available_k = list(range(1, min(p // 2, 25) + 1))
        # dominant_kã‚’available_kã«å«ã¾ã‚Œã‚‹å€¤ã®ã¿ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        dominant_k = [d[0] for d in dominant[:5] if d[0] in available_k]
        default_k = dominant_k[:3] if dominant_k else [1, 2, 3]

        col_select1, col_select2 = st.columns(2)
        with col_select1:
            selected_k = st.multiselect(
                "Compare frequencies",
                options=available_k,
                default=default_k,
                help="Select multiple k values to compare"
            )
        with col_select2:
            show_superposition = st.checkbox("Show superposition", value=True)
            show_learned = st.checkbox("Show learned embedding", value=True)

        if selected_k:
            # å€‹åˆ¥å‘¨æ³¢æ•°ã®æ¯”è¼ƒ
            st.markdown("#### Individual Frequency Components")

            fig_compare = make_subplots(
                rows=1, cols=len(selected_k),
                subplot_titles=[f"k={k}" for k in selected_k]
            )

            for idx, k in enumerate(selected_k):
                cos_basis = np.cos(2 * np.pi * k * n / p)
                sin_basis = np.sin(2 * np.pi * k * n / p)

                fig_compare.add_trace(
                    go.Scatter(x=n.tolist(), y=cos_basis.tolist(),
                              name=f"cos(2Ï€k{k}n/p)", line=dict(color="#2196F3")),
                    row=1, col=idx+1
                )
                fig_compare.add_trace(
                    go.Scatter(x=n.tolist(), y=sin_basis.tolist(),
                              name=f"sin(2Ï€k{k}n/p)", line=dict(color="#F44336")),
                    row=1, col=idx+1
                )

            fig_compare.update_layout(height=300, showlegend=False,
                                     plot_bgcolor="black", paper_bgcolor="black",
                                     font=dict(color="white"))
            fig_compare.update_xaxes(title_text="n", showgrid=True, gridcolor="rgba(255,255,255,0.1)")
            fig_compare.update_yaxes(showgrid=True, gridcolor="rgba(255,255,255,0.1)")
            st.plotly_chart(fig_compare, use_container_width=True)

            # é‡ã­åˆã‚ã›ã¨å­¦ç¿’æ¸ˆã¿åŸ‹ã‚è¾¼ã¿ã®æ¯”è¼ƒ
            st.markdown("#### Superposition vs Learned Embedding")
            st.markdown("""
            <div style="background: rgba(78, 205, 196, 0.1); padding: 10px; border-radius: 5px; margin-bottom: 10px;">
            <b>è¦‹æ–¹:</b> ç·‘ç·šï¼ˆç†è«–ï¼‰ã¨ã‚ªãƒ¬ãƒ³ã‚¸ç·šï¼ˆå­¦ç¿’æ¸ˆã¿ï¼‰ãŒ<b>ä¸€è‡´ã™ã‚‹ã»ã©è‰¯ã„</b>ã€‚<br>
            â€¢ <b>Superposition</b>: é¸æŠã—ãŸå‘¨æ³¢æ•°kã®cos/sinã‚’é‡ã­åˆã‚ã›ãŸç†è«–çš„ãªæ³¢å½¢<br>
            â€¢ <b>Learned Embedding</b>: ãƒ¢ãƒ‡ãƒ«ãŒå®Ÿéš›ã«å­¦ç¿’ã—ãŸåŸ‹ã‚è¾¼ã¿ã®æœ€å¤§åˆ†æ•£æ¬¡å…ƒ<br>
            â†’ ä¸€è‡´ = ãƒ¢ãƒ‡ãƒ«ãŒãƒ•ãƒ¼ãƒªã‚¨è¡¨ç¾ã‚’æ­£ã—ãå­¦ç¿’ã—ã¦ã„ã‚‹è¨¼æ‹ 
            </div>
            """, unsafe_allow_html=True)

            # æœ€ã‚‚åˆ†æ•£ãŒå¤§ãã„æ¬¡å…ƒã‚’å–å¾—
            variances = np.var(weights, axis=0)
            top_dim = np.argsort(variances)[-1]
            learned_dim = weights[:, top_dim]
            learned_norm = (learned_dim - learned_dim.mean()) / (learned_dim.std() + 1e-8)

            fig_super = go.Figure()

            # é‡ã­åˆã‚ã›ã‚’è¨ˆç®—
            if show_superposition and len(selected_k) > 0:
                superposition = np.zeros(p)
                for k in selected_k:
                    # å„å‘¨æ³¢æ•°ã®cos/sinã‚’å­¦ç¿’æ¸ˆã¿åŸ‹ã‚è¾¼ã¿ã¨ã®ç›¸é–¢ã§é‡ã¿ä»˜ã‘
                    cos_basis = np.cos(2 * np.pi * k * n / p)
                    sin_basis = np.sin(2 * np.pi * k * n / p)

                    cos_corr = np.corrcoef(learned_dim, cos_basis)[0, 1]
                    sin_corr = np.corrcoef(learned_dim, sin_basis)[0, 1]

                    if not np.isnan(cos_corr):
                        superposition += cos_corr * cos_basis
                    if not np.isnan(sin_corr):
                        superposition += sin_corr * sin_basis

                # æ­£è¦åŒ–
                if superposition.std() > 0:
                    superposition = (superposition - superposition.mean()) / superposition.std()

                fig_super.add_trace(go.Scatter(
                    x=n.tolist(), y=superposition.tolist(),
                    name=f"Superposition (k={','.join(map(str, selected_k))})",
                    line=dict(color="#4CAF50", width=2)
                ))

            # å­¦ç¿’æ¸ˆã¿åŸ‹ã‚è¾¼ã¿
            if show_learned:
                fig_super.add_trace(go.Scatter(
                    x=n.tolist(), y=learned_norm.tolist(),
                    name=f"Learned (dim {top_dim})",
                    line=dict(color="#FF9800", width=2, dash="dash")
                ))

            fig_super.update_layout(
                title="Fourier Superposition vs Learned Embedding",
                xaxis_title="Token n",
                yaxis_title="Normalized Value",
                height=400,
                plot_bgcolor="black",
                paper_bgcolor="black",
                font=dict(color="white"),
                legend=dict(orientation="h", y=-0.15)
            )
            fig_super.update_xaxes(showgrid=True, gridcolor="rgba(255,255,255,0.1)")
            fig_super.update_yaxes(showgrid=True, gridcolor="rgba(255,255,255,0.1)")
            st.plotly_chart(fig_super, use_container_width=True)

            # ç›¸é–¢è¡¨
            st.markdown("#### Correlation with Fourier Bases")
            corr_data = []
            for k in selected_k:
                cos_basis = np.cos(2 * np.pi * k * n / p)
                sin_basis = np.sin(2 * np.pi * k * n / p)
                cos_corr = np.corrcoef(learned_dim, cos_basis)[0, 1]
                sin_corr = np.corrcoef(learned_dim, sin_basis)[0, 1]
                combined = np.sqrt(cos_corr**2 + sin_corr**2) if not (np.isnan(cos_corr) or np.isnan(sin_corr)) else 0
                corr_data.append({
                    "k": k,
                    "cos correlation": f"{cos_corr:.3f}" if not np.isnan(cos_corr) else "N/A",
                    "sin correlation": f"{sin_corr:.3f}" if not np.isnan(sin_corr) else "N/A",
                    "combined": f"{combined:.3f}"
                })
            st.dataframe(pd.DataFrame(corr_data), use_container_width=True)

        st.markdown("---")
        st.subheader("Single Frequency Comparison")
        st.markdown("""
        <div style="background: rgba(255, 215, 0, 0.1); padding: 10px; border-radius: 5px; margin-bottom: 10px;">
        <b>è¦‹æ–¹:</b> ä¸»è¦å‘¨æ³¢æ•°kã«å¯¾ã™ã‚‹cos/sinã¨å­¦ç¿’æ¸ˆã¿åŸ‹ã‚è¾¼ã¿ã®æ¯”è¼ƒ<br>
        â€¢ <b>é’ç·š cos</b>ã¨<b>èµ¤ç·š sin</b>: ç†è«–çš„ãªãƒ•ãƒ¼ãƒªã‚¨åŸºåº•<br>
        â€¢ <b>ç·‘ç‚¹ç·š</b>: å­¦ç¿’æ¸ˆã¿åŸ‹ã‚è¾¼ã¿ï¼ˆæœ€å¤§åˆ†æ•£æ¬¡å…ƒï¼‰<br>
        â†’ ç·‘ç·šãŒcos/sinã®ã©ã¡ã‚‰ã‹ã«è¿‘ã„å½¢ = ãã®å‘¨æ³¢æ•°ã‚’å­¦ç¿’ã—ã¦ã„ã‚‹
        </div>
        """, unsafe_allow_html=True)
        fig_comparison = plot_fourier_basis_comparison(analyzer, dominant)
        if fig_comparison:
            st.plotly_chart(fig_comparison, use_container_width=True)

    with tab3:
        st.header("â±ï¸ Training Evolution")

        # è§£èª¬
        with st.expander("ğŸ“š å­¦ç¿’é€²åŒ–ã®è¦‹æ–¹", expanded=False):
            st.markdown("""
            **Training Evolution** ã§ã¯ã€å­¦ç¿’ä¸­ã«ãƒ¢ãƒ‡ãƒ«ã®å†…éƒ¨è¡¨ç¾ãŒã©ã†å¤‰åŒ–ã™ã‚‹ã‹ã‚’è¿½è·¡ã—ã¾ã™ã€‚

            ### å††ç’°æ§‹é€ ã®å½¢æˆéç¨‹
            å­¦ç¿’ãŒé€²ã‚€ã«ã¤ã‚Œã¦ã€ãƒ¢ãƒ‡ãƒ«ã®å†…éƒ¨è¡¨ç¾ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«å¤‰åŒ–ã—ã¾ã™ï¼š

            1. **åˆæœŸï¼ˆãƒ©ãƒ³ãƒ€ãƒ ï¼‰**: ç‚¹ãŒãƒãƒ©ãƒãƒ©ã«åˆ†å¸ƒ
            2. **è¨˜æ†¶ãƒ•ã‚§ãƒ¼ã‚º**: å°‘ã—ãšã¤æ§‹é€ ãŒç¾ã‚Œå§‹ã‚ã‚‹
            3. **æ±åŒ–ãƒ•ã‚§ãƒ¼ã‚º**: ãã‚Œã„ãªå††ç’°æ§‹é€ ãŒå½¢æˆã•ã‚Œã‚‹ â† **Grokkingå®Œäº†!**

            ### ã‚°ãƒ©ãƒ•ã®è¦‹æ–¹
            - **å·¦: å††ç’°ãƒ—ãƒ­ãƒƒãƒˆ** - å„ç‚¹ã¯ (a+b) mod p ã®å€¤ã‚’è¡¨ã™
            - **å³: ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ç›¸é–¢** - ãƒ•ãƒ¼ãƒªã‚¨æ¬¡å…ƒé–“ã®ç›¸é–¢
            - **è‰²**: ãƒ¬ã‚¤ãƒ³ãƒœãƒ¼ã‚«ãƒ©ãƒ¼ã§ 0â†’p-1 ã‚’è¡¨ç¾

            ### è‰¯ã„å­¦ç¿’ã®æŒ‡æ¨™
            - ç‚¹ãŒå††å‘¨ä¸Šã«ç­‰é–“éš”ã§ä¸¦ã¶
            - è§’åº¦ç›¸é–¢ï¼ˆAngle Corrï¼‰ãŒ 0.9 ä»¥ä¸Š
            - è‰²ãŒè™¹ã®é †åºã§ä¸¦ã¶
            """)

        # ãƒ•ãƒ¼ãƒªã‚¨å±¥æ­´ãŒã‚ã‚Œã°è¡¨ç¤º
        if os.path.exists(fourier_path):
            fourier_history = load_fourier_history(fourier_path)
            fig_evolution = plot_fourier_evolution(fourier_history)
            st.plotly_chart(fig_evolution, use_container_width=True)

        # ã‚¨ãƒãƒƒã‚¯ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’å–å¾—
        epoch_checkpoints = glob.glob(os.path.join(selected_dir, "epoch_*.pt")) + glob.glob(os.path.join(selected_dir, "checkpoint_epoch_*.pt"))

        if epoch_checkpoints:
            epochs_available = sorted([
                int(os.path.basename(f).replace("checkpoint_epoch_", "").replace("epoch_", "").replace(".pt", ""))
                for f in epoch_checkpoints
            ])

            if epochs_available:
                st.subheader("Epoch Selector")

                # ç¯„å›²ã‚’çµã‚‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³
                col_range1, col_range2 = st.columns(2)
                with col_range1:
                    start_idx = st.number_input("Start epoch", min_value=epochs_available[0],
                                                max_value=epochs_available[-1], value=epochs_available[0], step=10)
                with col_range2:
                    end_idx = st.number_input("End epoch", min_value=epochs_available[0],
                                              max_value=epochs_available[-1], value=min(epochs_available[-1], 1000), step=10)

                # ç¯„å›²å†…ã®ã‚¨ãƒãƒƒã‚¯ã‚’ãƒ•ã‚£ãƒ«ã‚¿
                filtered_epochs = [e for e in epochs_available if start_idx <= e <= end_idx]
                if not filtered_epochs:
                    filtered_epochs = epochs_available

                selected_epoch = st.select_slider(
                    "Select Epoch",
                    options=filtered_epochs,
                    value=filtered_epochs[-1]
                )

                epoch_path = get_epoch_path(selected_dir, selected_epoch)
                if epoch_path:
                    epoch_model, _, _ = load_model(epoch_path)
                    epoch_analyzer = FourierAnalyzer(epoch_model)

                    col1, col2 = st.columns(2)
                    with col1:
                        fig_circle_epoch, _ = plot_embedding_circle(epoch_analyzer)
                        st.plotly_chart(fig_circle_epoch, use_container_width=True, key=f"evolution_circle_{selected_epoch}")
                    with col2:
                        fig_spectrum_epoch, _ = plot_fourier_spectrum(epoch_analyzer)
                        st.plotly_chart(fig_spectrum_epoch, use_container_width=True, key=f"evolution_spectrum_{selected_epoch}")
        else:
            st.warning("No epoch checkpoints found in this directory.")

    with tab4:
        st.header("ğŸ¯ Model Output Analysis")

        # è§£èª¬
        with st.expander("ğŸ“š ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ã®è¦‹æ–¹", expanded=False):
            st.markdown("""
            **Model Output Analysis** ã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬çµæœã‚’2D/3Dã§å¯è¦–åŒ–ã—ã¾ã™ã€‚

            ### 2ã¤ã®è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰
            | ãƒ¢ãƒ¼ãƒ‰ | å†…å®¹ | ç‰¹å¾´ |
            |--------|------|------|
            | **Predictions (Cyclic)** | äºˆæ¸¬å€¤ï¼ˆé›¢æ•£ï¼‰ | ãƒ¢ã‚¸ãƒ¥ãƒ©æ¼”ç®—ã®å‘¨æœŸæ€§ãŒè¦‹ãˆã‚‹ |
            | **Logits (Continuous)** | å‡ºåŠ›ãƒ­ã‚¸ãƒƒãƒˆï¼ˆé€£ç¶šï¼‰ | æ»‘ã‚‰ã‹ãªæ³¢é¢ãŒè¦‹ãˆã‚‹ |

            ### 2D Heatmap ã®è¦‹æ–¹
            - **æ¨ªè»¸**: å…¥åŠ› b
            - **ç¸¦è»¸**: å…¥åŠ› a
            - **è‰²**: äºˆæ¸¬å€¤ or ãƒ­ã‚¸ãƒƒãƒˆå€¤
            - **ãƒ‘ã‚¿ãƒ¼ãƒ³**: æ–œã‚ã®ç¸æ¨¡æ§˜ãŒæ­£ã—ã„ï¼ˆ(a+b) mod p ã®ç­‰é«˜ç·šï¼‰

            ### 3D Surface ã®è¦‹æ–¹
            - **æ³¢é¢ã®å½¢çŠ¶**: cos(Ï‰(a+b)) ã®ã‚ˆã†ãªæ³¢å½¢ãŒè¦‹ãˆã‚‹ã¯ãš
            - **æ»‘ã‚‰ã‹ã•**: Logitsãƒ¢ãƒ¼ãƒ‰ã§æ»‘ã‚‰ã‹ãªè¡¨é¢ãŒè¦‹ãˆã‚Œã°å­¦ç¿’æˆåŠŸ

            ### ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—ã®é¸æŠ
            - **HSV/Phase**: å¾ªç’°ãƒ‡ãƒ¼ã‚¿ã«æœ€é©ï¼ˆ0ã¨p-1ãŒåŒã˜è‰²ï¼‰
            - **Twilight**: å‘¨æœŸæ€§ã‚’å¼·èª¿
            """)

        fig_matrix, accuracy, pred_matrix, logit_matrix = plot_mlp_output_matrix(model, config)
        p = config["p"]

        st.metric("Model Accuracy", f"{accuracy:.1f}%")

        # ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—é¸æŠ
        col_mode, col_cmap = st.columns(2)
        with col_mode:
            view_mode = st.radio(
                "View Mode",
                ["Predictions (Cyclic)", "Logits (Continuous)"],
                horizontal=True
            )
        with col_cmap:
            # å¾ªç’°å‹ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—ã‚ªãƒ—ã‚·ãƒ§ãƒ³
            cyclical_cmaps = ["HSV", "Phase", "Edge", "IceFire", "Twilight"]
            selected_cmap = st.selectbox("Colormap (cyclical)", cyclical_cmaps, index=0)

        # 2Dã¨3Dã‚’ä¸¦ã¹ã¦è¡¨ç¤º
        col_2d, col_3d = st.columns(2)

        if view_mode == "Predictions (Cyclic)":
            with col_2d:
                st.subheader("2D Heatmap")
                # å¾ªç’°å‹ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—ã§äºˆæ¸¬å€¤ã‚’è¡¨ç¤º
                fig_2d_cyclic = go.Figure(data=go.Heatmap(
                    z=pred_matrix,
                    colorscale=selected_cmap,
                    zmin=0, zmax=p,  # 0ã€œp-1ã§å¾ªç’°
                    colorbar=dict(title=f"(a+b) mod {p}", tickvals=[0, p//4, p//2, 3*p//4, p-1])
                ))
                fig_2d_cyclic.update_layout(
                    xaxis_title="b", yaxis_title="a",
                    height=500, plot_bgcolor="black", paper_bgcolor="black",
                    font=dict(color="white")
                )
                st.plotly_chart(fig_2d_cyclic, use_container_width=True)
            with col_3d:
                st.subheader("3D Surface")
                fig_3d_pred = go.Figure(data=[go.Surface(
                    z=pred_matrix,
                    colorscale=selected_cmap,
                    cmin=0, cmax=p,
                    showscale=True,
                    colorbar=dict(title=f"(a+b) mod {p}")
                )])
                fig_3d_pred.update_layout(
                    scene=dict(xaxis_title="b", yaxis_title="a", zaxis_title="Prediction", bgcolor="black"),
                    height=500, paper_bgcolor="black", font=dict(color="white")
                )
                st.plotly_chart(fig_3d_pred, use_container_width=True)
        else:
            # Logitè¡¨ç¤ºï¼ˆæ»‘ã‚‰ã‹ãªæ³¢ï¼‰
            from scipy.ndimage import zoom
            smooth_logit = zoom(logit_matrix, 2, order=3)
            x = np.linspace(0, p-1, smooth_logit.shape[1])
            y = np.linspace(0, p-1, smooth_logit.shape[0])

            with col_2d:
                st.subheader("2D Heatmap (Logits)")
                fig_2d_smooth = go.Figure(data=go.Heatmap(
                    z=smooth_logit,
                    x=x,
                    y=y,
                    colorscale="Viridis",
                    colorbar=dict(title="Logit (confidence)")
                ))
                fig_2d_smooth.update_layout(
                    xaxis_title="b", yaxis_title="a",
                    height=500, plot_bgcolor="black", paper_bgcolor="black",
                    font=dict(color="white")
                )
                st.plotly_chart(fig_2d_smooth, use_container_width=True)

            with col_3d:
                st.subheader("3D Surface (Wave)")
                fig_3d = plot_mlp_output_3d(logit_matrix, config)
                st.plotly_chart(fig_3d, use_container_width=True)

        st.subheader("Test Predictions")

        col1, col2 = st.columns(2)
        n_tokens = config.get("n_tokens", 2)
        p = config["p"]

        with col1:
            a = st.number_input("a", min_value=0, max_value=p-1, value=0)
            b = st.number_input("b", min_value=0, max_value=p-1, value=0)
            if n_tokens == 3:
                c = st.number_input("c", min_value=0, max_value=p-1, value=0)

        with col2:
            if n_tokens == 2:
                x = torch.tensor([[a, b]])
                expected = (a + b) % p
            else:
                x = torch.tensor([[a, b, c]])
                expected = (a + b + c) % p

            with torch.no_grad():
                logits = model(x)
                pred = logits.argmax(dim=-1).item()
                probs = torch.softmax(logits, dim=-1).squeeze().numpy()

            is_correct = pred == expected
            color = "green" if is_correct else "red"

            st.markdown(f"""
            **Input:** {tuple(x.squeeze().tolist())}

            **Prediction:** <span style='color:{color};font-size:24px;'>{pred}</span>

            **Expected:** {expected}

            **Correct:** {'âœ…' if is_correct else 'âŒ'}
            """, unsafe_allow_html=True)

            # ç¢ºç‡åˆ†å¸ƒ
            fig_probs = go.Figure()
            fig_probs.add_trace(go.Bar(
                x=list(range(p)),
                y=probs.tolist(),
                marker_color=["green" if i == expected else "blue" for i in range(p)]
            ))
            fig_probs.update_layout(
                title="Output Probability Distribution",
                xaxis_title="Class",
                yaxis_title="Probability",
                height=300
            )
            st.plotly_chart(fig_probs, use_container_width=True)

    with tab5:
        st.header("ğŸ¬ Epoch Slider - å­¦ç¿’é€²æ—ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³")

        # è§£èª¬
        with st.expander("ğŸ“š ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã®è¦‹æ–¹", expanded=False):
            st.markdown("""
            **Epoch Slider** ã§ã¯ã€å­¦ç¿’ã®å„ã‚¨ãƒãƒƒã‚¯ã§ãƒ¢ãƒ‡ãƒ«ã®å†…éƒ¨è¡¨ç¾ãŒã©ã†å¤‰åŒ–ã™ã‚‹ã‹ã‚’ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã§ç¢ºèªã§ãã¾ã™ã€‚

            ### è¡¨ç¤ºå†…å®¹
            | ãƒ‘ãƒãƒ« | å†…å®¹ |
            |--------|------|
            | **å††ç’°ãƒ—ãƒ­ãƒƒãƒˆ** | å„ (a+b) mod p ã®å€¤ã®å†…éƒ¨è¡¨ç¾ã‚’2Dã«å°„å½± |
            | **å­¦ç¿’æ›²ç·š** | Train/Testç²¾åº¦ã®æ¨ç§»ï¼ˆç¾åœ¨ä½ç½®ã‚’è¡¨ç¤ºï¼‰ |
            | **ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ç›¸é–¢** | ãƒ•ãƒ¼ãƒªã‚¨æ¬¡å…ƒé–“ã®ç›¸é–¢è¡Œåˆ— |

            ### ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã®æ“ä½œ
            - **â–¶ï¸ Play**: ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³å†ç”Ÿ
            - **â¸ï¸ Pause**: ä¸€æ™‚åœæ­¢
            - **ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼**: ä»»æ„ã®ã‚¨ãƒãƒƒã‚¯ã«ã‚¸ãƒ£ãƒ³ãƒ—

            ### è¦‹ã‚‹ã¹ããƒã‚¤ãƒ³ãƒˆ
            1. **åˆæœŸ**: ç‚¹ãŒãƒ©ãƒ³ãƒ€ãƒ ã«åˆ†å¸ƒ
            2. **è¨˜æ†¶ãƒ•ã‚§ãƒ¼ã‚º**: Trainç²¾åº¦â†‘ã€Testç²¾åº¦ã¯ä½ã„ã¾ã¾
            3. **Grokking**: Testç²¾åº¦ãŒæ€¥ä¸Šæ˜‡ã€å††ç’°ãŒå½¢æˆã•ã‚Œã‚‹
            4. **æœ€çµ‚çŠ¶æ…‹**: ãã‚Œã„ãªå††ç’° + é«˜ã„è§’åº¦ç›¸é–¢

            ### æ¤œå‡ºæ¬¡å…ƒã«ã¤ã„ã¦
            - **cosæ¬¡å…ƒ/sinæ¬¡å…ƒ**: æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã§æ¤œå‡ºã—ãŸãƒ•ãƒ¼ãƒªã‚¨ãƒšã‚¢
            - ã“ã®æ¬¡å…ƒãƒšã‚¢ã‚’å…¨ã‚¨ãƒãƒƒã‚¯ã§å›ºå®šã—ã¦è¿½è·¡
            """)

        if os.path.exists(history_path):
            history = load_history(history_path)

            # åˆ©ç”¨å¯èƒ½ãªã‚¨ãƒãƒƒã‚¯ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’å–å¾—
            epoch_checkpoints = glob.glob(os.path.join(selected_dir, "epoch_*.pt")) + glob.glob(os.path.join(selected_dir, "checkpoint_epoch_*.pt"))
            if epoch_checkpoints:
                epochs_available = sorted([
                    int(os.path.basename(f).replace("checkpoint_epoch_", "").replace("epoch_", "").replace(".pt", ""))
                    for f in epoch_checkpoints
                ])

                if epochs_available:
                    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³
                    if st.button("ğŸ”„ Clear Cache", key="clear_cache_btn"):
                        st.cache_data.clear()
                        st.rerun()

                    # ãƒ•ãƒ¼ãƒªã‚¨åŸºåº•ã¨ã®ç›¸é–¢ãŒé«˜ã„æ¬¡å…ƒã‚’è¨ˆç®—
                    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆæ•°ã‚’å«ã‚ã‚‹
                    n_checkpoints = len(epochs_available)

                    @st.cache_data
                    def get_fourier_dims(_dir, _p, _n_tokens, _d_model, _n_cp, n_dims=10):
                        """ãƒ•ãƒ¼ãƒªã‚¨åŸºåº•ã¨ã®ç›¸é–¢ãŒé«˜ã„æ¬¡å…ƒã‚’å–å¾—ï¼ˆcos/sinæ¬¡å…ƒãƒšã‚¢ã‚‚æ¤œå‡ºï¼‰"""
                        p = _p
                        n_tokens = _n_tokens

                        # æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
                        best_path = os.path.join(_dir, "best.pt")
                        final_path = os.path.join(_dir, "final.pt")
                        if os.path.exists(best_path):
                            ref_path = best_path
                        elif os.path.exists(final_path):
                            ref_path = final_path
                        else:
                            # checkpoint_epoch_*.pt ã‹ã‚‰æœ€æ–°ã‚’å–å¾—
                            epoch_files = sorted([f for f in os.listdir(_dir)
                                                 if f.startswith("checkpoint_epoch_") and f.endswith(".pt")])
                            if epoch_files:
                                ref_path = os.path.join(_dir, epoch_files[-1])
                            else:
                                return None, None, None, None

                        ref_model, _, _ = load_model(ref_path)

                        # å„(a+b) mod p ã®å€¤ã«å¯¾ã™ã‚‹åŸ‹ã‚è¾¼ã¿ã‚’è¨ˆç®—
                        sum_embeddings = np.zeros((p, _d_model))
                        samples_per_sum = 5

                        all_pairs = []
                        sum_labels = []
                        for s in range(p):
                            for i in range(samples_per_sum):
                                a = (s + i * 17) % p
                                b = (s - a) % p
                                all_pairs.append([a, b])
                                sum_labels.append(s)

                        if n_tokens == 2:
                            inputs = torch.tensor(all_pairs)
                        else:
                            inputs = torch.tensor([[a, b, 0] for a, b in all_pairs])

                        with torch.no_grad():
                            _, intermediates = ref_model.forward_with_intermediates(inputs)
                        pooled = intermediates["pooled"].numpy()

                        # å„å’Œå€¤ã”ã¨ã«å¹³å‡
                        sum_labels = np.array(sum_labels)
                        for s in range(p):
                            mask = sum_labels == s
                            sum_embeddings[s] = pooled[mask].mean(axis=0)

                        # æœ€è‰¯ã®cos/sinæ¬¡å…ƒãƒšã‚¢ã‚’æ¤œå‡º
                        s_values = np.arange(p)
                        best_k = 1
                        best_cos_dim = 0
                        best_sin_dim = 1
                        best_total_corr = 0
                        all_dim_info = []  # å„æ¬¡å…ƒã®æƒ…å ±ã‚’ä¿å­˜

                        for k in range(1, min(p // 4, 20) + 1):
                            cos_basis = np.cos(2 * np.pi * k * s_values / p)
                            sin_basis = np.sin(2 * np.pi * k * s_values / p)

                            cos_corrs = []
                            sin_corrs = []
                            for d in range(_d_model):
                                dim_vals = sum_embeddings[:, d]
                                if np.std(dim_vals) > 0.01:
                                    cc = np.corrcoef(dim_vals, cos_basis)[0, 1]
                                    sc = np.corrcoef(dim_vals, sin_basis)[0, 1]
                                    cos_corrs.append((d, cc if not np.isnan(cc) else 0))
                                    sin_corrs.append((d, sc if not np.isnan(sc) else 0))
                                else:
                                    cos_corrs.append((d, 0))
                                    sin_corrs.append((d, 0))

                            # æœ€ã‚‚cos/sinã«ç›¸é–¢ãŒé«˜ã„æ¬¡å…ƒã‚’è¦‹ã¤ã‘ã‚‹
                            cos_corrs.sort(key=lambda x: abs(x[1]), reverse=True)
                            sin_corrs.sort(key=lambda x: abs(x[1]), reverse=True)

                            cos_dim = cos_corrs[0][0]
                            cos_val = abs(cos_corrs[0][1])
                            # sinæ¬¡å…ƒã¯cosæ¬¡å…ƒã¨ç•°ãªã‚‹ã‚‚ã®ã‚’é¸ã¶
                            sin_dim = sin_corrs[0][0] if sin_corrs[0][0] != cos_dim else sin_corrs[1][0]
                            sin_val = abs(sin_corrs[0][1]) if sin_corrs[0][0] != cos_dim else abs(sin_corrs[1][1])

                            total_corr = cos_val + sin_val
                            if total_corr > best_total_corr:
                                best_total_corr = total_corr
                                best_k = k
                                best_cos_dim = cos_dim
                                best_sin_dim = sin_dim

                        # å„æ¬¡å…ƒã®ãƒ•ãƒ¼ãƒªã‚¨ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
                        fourier_scores = []
                        best_k_per_dim = []

                        for dim in range(_d_model):
                            dim_vals = sum_embeddings[:, dim]
                            best_corr = 0
                            best_dim_k = 1

                            for k in range(1, min(p // 4, 20) + 1):
                                cos_basis = np.cos(2 * np.pi * k * s_values / p)
                                sin_basis = np.sin(2 * np.pi * k * s_values / p)

                                if np.std(dim_vals) > 0.01:
                                    cos_corr = abs(np.corrcoef(dim_vals, cos_basis)[0, 1])
                                    sin_corr = abs(np.corrcoef(dim_vals, sin_basis)[0, 1])
                                    if not np.isnan(cos_corr) and cos_corr > best_corr:
                                        best_corr = cos_corr
                                        best_dim_k = k
                                    if not np.isnan(sin_corr) and sin_corr > best_corr:
                                        best_corr = sin_corr
                                        best_dim_k = k

                            fourier_scores.append(best_corr)
                            best_k_per_dim.append(best_dim_k)

                        # ãƒ•ãƒ¼ãƒªã‚¨ç›¸é–¢ãŒé«˜ã„æ¬¡å…ƒã‚’é¸æŠ
                        top_indices = np.argsort(fourier_scores)[::-1][:n_dims]
                        top_dims = top_indices.tolist()
                        top_k = [best_k_per_dim[i] for i in top_indices]
                        top_corrs = [fourier_scores[i] for i in top_indices]

                        # cos/sinæ¬¡å…ƒãƒšã‚¢æƒ…å ±
                        best_pair = {
                            "k": best_k,
                            "cos_dim": best_cos_dim,
                            "sin_dim": best_sin_dim,
                            "total_corr": best_total_corr
                        }

                        return top_dims, top_k, top_corrs, best_pair

                    fixed_dims, fourier_k, fourier_corrs, best_pair = get_fourier_dims(
                        selected_dir, config["p"], config.get("n_tokens", 2), config.get("d_model", 128),
                        n_checkpoints, n_dims=10
                    )

                    if fixed_dims and best_pair:
                        # è¡¨ç¤ºç”¨ã«æ•´å½¢
                        dim_info = ", ".join([f"d{d}(k={k})" for d, k in zip(fixed_dims[:5], fourier_k[:5])])
                        pair_info = f"æœ€è‰¯ãƒšã‚¢: cos=d{best_pair['cos_dim']}, sin=d{best_pair['sin_dim']} (k={best_pair['k']}, corr={best_pair['total_corr']:.3f})"
                        st.success(f"ãƒ•ãƒ¼ãƒªã‚¨æ¤œå‡ºæ¬¡å…ƒï¼ˆä¸Šä½10ï¼‰: {dim_info}...")
                        st.info(pair_info)
                    else:
                        st.warning("æ¬¡å…ƒã®æ¤œå‡ºã«å¤±æ•—ã—ã¾ã—ãŸ")
                        best_pair = {"k": 1, "cos_dim": 0, "sin_dim": 1, "total_corr": 0}

                    # äº‹å‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥: å…¨ã‚¨ãƒãƒƒã‚¯ã®å¯è¦–åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
                    @st.cache_data(show_spinner="ã‚¨ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ—ãƒªãƒ­ãƒ¼ãƒ‰ä¸­...")
                    def preload_epoch_data(_dir, _p, _n_tokens, _n_cp, _epochs, _fixed_dims, _best_pair_tuple, sample_step=1):
                        """å…¨ã‚¨ãƒãƒƒã‚¯ã®å¯è¦–åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’äº‹å‰è¨ˆç®—ï¼ˆå›ºå®šæ¬¡å…ƒãƒšã‚¢ã‚’ä½¿ç”¨ï¼‰"""
                        p = _p
                        n_tokens = _n_tokens

                        # æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã§æ¤œå‡ºã—ãŸå›ºå®šæ¬¡å…ƒãƒšã‚¢ã‚’ä½¿ç”¨ï¼ˆã‚¿ãƒ—ãƒ«ã‹ã‚‰å±•é–‹ï¼‰
                        fixed_k, fixed_cos_dim, fixed_sin_dim = _best_pair_tuple

                        # å††ç’°ç”¨: å„å’Œå€¤ã«å¯¾ã—ã¦è¤‡æ•°ã‚µãƒ³ãƒ—ãƒ«ã‚’ç”¨æ„ã—ã¦å¹³å‡ã‚’å–ã‚‹ï¼ˆè»½é‡åŒ–ï¼‰
                        np.random.seed(42)
                        samples_per_sum = 3  # 5â†’3ã«å‰Šæ¸›
                        all_circle_pairs = []
                        sum_labels = []

                        for s in range(p):
                            for i in range(samples_per_sum):
                                a = (s + i * 17) % p
                                b = (s - a) % p
                                all_circle_pairs.append([a, b])
                                sum_labels.append(s)

                        sum_labels = np.array(sum_labels)

                        # ç›¸é–¢è¡Œåˆ—ç”¨ã‚µãƒ³ãƒ—ãƒ«ï¼ˆè»½é‡åŒ–ï¼‰
                        corr_pairs = [[np.random.randint(p), np.random.randint(p)] for _ in range(100)]

                        if n_tokens == 2:
                            inputs_circle = torch.tensor(all_circle_pairs)
                            inputs_corr = torch.tensor(corr_pairs)
                        else:
                            inputs_circle = torch.tensor([[a, b, 0] for a, b in all_circle_pairs])
                            inputs_corr = torch.tensor([[a, b, 0] for a, b in corr_pairs])

                        epoch_data = {}
                        sampled_epochs = _epochs[::sample_step]

                        for ep in sampled_epochs:
                            ep_path = get_epoch_path(_dir, ep)
                            if ep_path is None:
                                continue

                            try:
                                ep_model, _, _ = load_model(ep_path)

                                with torch.no_grad():
                                    _, inter_circle = ep_model.forward_with_intermediates(inputs_circle)
                                    _, inter_corr = ep_model.forward_with_intermediates(inputs_corr)

                                pooled_all = inter_circle["pooled"].numpy()
                                pooled_corr = inter_corr["pooled"].numpy()

                                # å„å’Œå€¤ã”ã¨ã«å¹³å‡ã‚’å–ã‚‹
                                sum_embeddings = np.zeros((p, pooled_all.shape[1]))
                                for s in range(p):
                                    mask = sum_labels == s
                                    sum_embeddings[s] = pooled_all[mask].mean(axis=0)

                                # å›ºå®šã®æ¬¡å…ƒãƒšã‚¢ã‚’ä½¿ç”¨ï¼ˆæœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã§æ¤œå‡ºã—ãŸã‚‚ã®ï¼‰
                                proj_2d = sum_embeddings[:, [fixed_cos_dim, fixed_sin_dim]]

                                # å††ç’°æ€§ã‚’è¨ˆç®—ï¼ˆè§’åº¦ã¨ç†è«–è§’åº¦ã®ç›¸é–¢ï¼‰
                                center = proj_2d.mean(axis=0)
                                centered = proj_2d - center
                                angles = np.arctan2(centered[:, 1], centered[:, 0])
                                expected_angles = 2 * np.pi * fixed_k * np.arange(p) / p - np.pi

                                best_corr = 0
                                for shift in range(p):
                                    shifted_expected = np.roll(expected_angles, shift)
                                    corr = np.corrcoef(angles, shifted_expected)[0, 1]
                                    if not np.isnan(corr):
                                        best_corr = max(best_corr, abs(corr))

                                # ç›¸é–¢è¡Œåˆ—ç”¨ãƒ‡ãƒ¼ã‚¿
                                pooled_sampled = pooled_corr[:, _fixed_dims[:10]] if _fixed_dims else pooled_corr[:, :10]

                                epoch_data[ep] = {
                                    "proj_2d": proj_2d,  # (p, 2) - å„(a+b) mod p ã®è¡¨ç¾
                                    "angle_corr": best_corr,
                                    "pooled": pooled_sampled  # (200, 10)
                                }
                            except Exception as e:
                                continue

                        return epoch_data, sampled_epochs

                    # ã‚¨ãƒãƒƒã‚¯åˆ»ã¿è¨­å®š
                    col_step1, col_step2 = st.columns([1, 2])
                    with col_step1:
                        auto_step = st.checkbox("è‡ªå‹•åˆ»ã¿", value=True, help="ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ãŒ50ä»¥ä¸‹ã«ãªã‚‹ã‚ˆã†è‡ªå‹•èª¿æ•´")
                    with col_step2:
                        if auto_step:
                            sample_step = max(1, len(epochs_available) // 30)  # 50â†’30ãƒ•ãƒ¬ãƒ¼ãƒ ã«å‰Šæ¸›
                            st.info(f"è‡ªå‹•è¨­å®š: {sample_step}ã‚¨ãƒãƒƒã‚¯é–“éš”ï¼ˆç´„30ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰")
                        else:
                            sample_step = st.number_input(
                                "ã‚¨ãƒãƒƒã‚¯åˆ»ã¿",
                                min_value=1,
                                max_value=max(1, len(epochs_available) // 5),
                                value=10,
                                step=5,
                                help="ä½•ã‚¨ãƒãƒƒã‚¯ã”ã¨ã«ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆã™ã‚‹ã‹"
                            )

                    # best_pairã‚’ã‚¿ãƒ—ãƒ«ã«å¤‰æ›ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ç”¨ï¼‰
                    best_pair_tuple = (best_pair["k"], best_pair["cos_dim"], best_pair["sin_dim"])

                    with st.spinner("ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ—ãƒªãƒ­ãƒ¼ãƒ‰ä¸­..."):
                        epoch_data, sampled_epochs = preload_epoch_data(
                            selected_dir, config["p"], config.get("n_tokens", 2),
                            n_checkpoints, epochs_available, fixed_dims, best_pair_tuple, sample_step
                        )

                    st.info(f"ãƒ—ãƒªãƒ­ãƒ¼ãƒ‰å®Œäº†: {len(epoch_data)}ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆ{sample_step}ã‚¨ãƒãƒƒã‚¯é–“éš”ï¼‰")

                    # Plotlyã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ä½œæˆï¼ˆå­¦ç¿’æ›²ç·šçµ±åˆç‰ˆï¼‰
                    if epoch_data:
                        grid_size = 7  # 7x7ã‚°ãƒªãƒƒãƒ‰
                        first_ep = sampled_epochs[0]
                        first_data = epoch_data.get(first_ep, {})

                        # å…¨ã‚¨ãƒãƒƒã‚¯ã‹ã‚‰è»¸ã®ç¯„å›²ã‚’è¨ˆç®—ï¼ˆå›ºå®šç”¨ï¼‰
                        all_proj_x, all_proj_y = [], []
                        all_pooled = [[] for _ in range(grid_size)]
                        for ep_data in epoch_data.values():
                            proj = ep_data["proj_2d"]
                            pooled = ep_data["pooled"]
                            all_proj_x.extend(proj[:, 0].tolist())
                            all_proj_y.extend(proj[:, 1].tolist())
                            for i in range(min(grid_size, pooled.shape[1])):
                                all_pooled[i].extend(pooled[:, i].tolist())

                        # è»¸ç¯„å›²ã‚’è¨ˆç®—ï¼ˆ10%ãƒãƒ¼ã‚¸ãƒ³ï¼‰
                        def calc_range(data):
                            if not data:
                                return [-1, 1]
                            mn, mx = min(data), max(data)
                            margin = (mx - mn) * 0.1 + 0.01
                            return [mn - margin, mx + margin]

                        proj_x_range = calc_range(all_proj_x)
                        proj_y_range = calc_range(all_proj_y)
                        pooled_ranges = [calc_range(d) for d in all_pooled]

                        # å­¦ç¿’æ›²ç·šãƒ‡ãƒ¼ã‚¿
                        epochs_list = list(range(1, len(history["train_acc"]) + 1))
                        train_acc = [a * 100 for a in history["train_acc"]]
                        test_acc = [a * 100 for a in history["test_acc"]]

                        # ãƒˆãƒ¬ãƒ¼ã‚¹æ•°: åŸ‹ã‚è¾¼ã¿(1) + ç›¸é–¢è¡Œåˆ—(25) + å­¦ç¿’æ›²ç·š(2) + ç¸¦ç·š(1) = 29
                        n_corr_traces = grid_size * grid_size

                        # ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
                        frames = []
                        slider_steps = []

                        for ep in sampled_epochs:
                            if ep not in epoch_data:
                                continue
                            data = epoch_data[ep]
                            proj = data["proj_2d"]
                            pooled = data["pooled"]
                            angle_corr = data.get("angle_corr", 0)

                            frame_traces = []

                            # åŸ‹ã‚è¾¼ã¿ç©ºé–“ï¼ˆ(a+b) mod p ã®å€¤ã§è‰²åˆ†ã‘ - å††ç’°ä¸Šã«é…ç½®ã•ã‚Œã‚‹ã¯ãšï¼‰
                            # proj ã®å„ç‚¹ã¯ sum=0,1,...,p-1 ã®é †
                            p_val = config["p"]

                            # ç‚¹ã‚’ç·šã§çµã¶ï¼ˆå††ã‚’å½¢æˆã™ã‚‹ã¯ãšï¼‰
                            x_line = proj[:, 0].tolist() + [proj[0, 0]]
                            y_line = proj[:, 1].tolist() + [proj[0, 1]]

                            frame_traces.append(go.Scatter(
                                x=x_line,
                                y=y_line,
                                mode="lines",
                                line=dict(color="rgba(128,128,128,0.3)", width=1),
                                showlegend=False
                            ))

                            frame_traces.append(go.Scatter(
                                x=proj[:, 0].tolist(),
                                y=proj[:, 1].tolist(),
                                mode="markers",
                                marker=dict(
                                    color=list(range(p_val)),
                                    colorscale="HSV",  # HSVã§å††ç’°çŠ¶ã®è‰²ã‚’è¡¨ç¾
                                    size=6,
                                    opacity=0.9
                                ),
                                showlegend=False
                            ))

                            # 5x5ç›¸é–¢è¡Œåˆ—ï¼ˆå…¥åŠ›å€¤ã§è‰²åˆ†ã‘ï¼‰
                            for i in range(grid_size):
                                for j in range(grid_size):
                                    frame_traces.append(go.Scatter(
                                        x=pooled[:, j].tolist(),
                                        y=pooled[:, i].tolist(),
                                        mode="markers",
                                        marker=dict(
                                            color=list(range(len(pooled))),
                                            colorscale="Plasma",
                                            size=3,
                                            opacity=0.6
                                        ),
                                        showlegend=False
                                    ))

                            # å­¦ç¿’æ›²ç·šï¼ˆå›ºå®šï¼‰
                            frame_traces.append(go.Scatter(
                                x=epochs_list, y=train_acc,
                                mode="lines", line=dict(color="#2196F3", width=1.5),
                                showlegend=False
                            ))
                            frame_traces.append(go.Scatter(
                                x=epochs_list, y=test_acc,
                                mode="lines", line=dict(color="#F44336", width=1.5),
                                showlegend=False
                            ))

                            # ç¾åœ¨ä½ç½®ã®ç¸¦ç·š
                            frame_traces.append(go.Scatter(
                                x=[ep, ep], y=[0, 100],
                                mode="lines", line=dict(color="#FFFF00", width=2),
                                showlegend=False
                            ))

                            frames.append(go.Frame(
                                data=frame_traces,
                                name=str(ep),
                                layout=go.Layout(
                                    annotations=[dict(
                                        text=f"Epoch {ep} | Train: {train_acc[min(ep-1, len(train_acc)-1)]:.1f}% | Test: {test_acc[min(ep-1, len(test_acc)-1)]:.1f}% | Circle: {angle_corr:.2f}",
                                        xref="paper", yref="paper",
                                        x=0.5, y=1.02, showarrow=False,
                                        font=dict(size=14, color="white")
                                    )]
                                )
                            ))

                            slider_steps.append({
                                "args": [[str(ep)], {
                                    "frame": {"duration": 100, "redraw": False},
                                    "transition": {"duration": 50, "easing": "linear"},
                                    "mode": "immediate"
                                }],
                                "label": str(ep),
                                "method": "animate"
                            })

                        # ãƒ¡ã‚¤ãƒ³figure: 8è¡Œ8åˆ—ï¼ˆ7x7ç›¸é–¢è¡Œåˆ— + 1è¡Œå­¦ç¿’æ›²ç·šã€å·¦ã«åŸ‹ã‚è¾¼ã¿ï¼‰
                        # ã‚°ãƒªãƒƒãƒ‰ã«ç¸¦å¹…ã‚’å¤šãå‰²ã‚Šå½“ã¦
                        grid_row_height = 0.12  # å„ã‚°ãƒªãƒƒãƒ‰è¡Œã®é«˜ã•
                        curve_row_height = 0.10  # å­¦ç¿’æ›²ç·šã®é«˜ã•
                        fig = make_subplots(
                            rows=grid_size + 1, cols=grid_size + 1,
                            column_widths=[0.28] + [0.103] * grid_size,
                            row_heights=[grid_row_height] * grid_size + [curve_row_height],
                            specs=[[{"rowspan": grid_size}] + [{}] * grid_size] +
                                  [[None] + [{}] * grid_size for _ in range(grid_size - 1)] +
                                  [[{"colspan": grid_size + 1}] + [None] * grid_size],
                            horizontal_spacing=0.008,
                            vertical_spacing=0.015
                        )

                        # åˆæœŸãƒ‡ãƒ¼ã‚¿
                        if first_data:
                            proj = first_data["proj_2d"]
                            pooled = first_data["pooled"]
                            p_val = config["p"]

                            # åŸ‹ã‚è¾¼ã¿ç©ºé–“: ç‚¹ã‚’çµã¶ç·šï¼ˆå††ã‚’å½¢æˆï¼‰
                            x_line = proj[:, 0].tolist() + [proj[0, 0]]
                            y_line = proj[:, 1].tolist() + [proj[0, 1]]
                            fig.add_trace(go.Scatter(
                                x=x_line,
                                y=y_line,
                                mode="lines",
                                line=dict(color="rgba(128,128,128,0.3)", width=1),
                                showlegend=False
                            ), row=1, col=1)

                            # åŸ‹ã‚è¾¼ã¿ç©ºé–“: æ•£å¸ƒå›³ï¼ˆ(a+b) mod p ã§è‰²åˆ†ã‘ï¼‰
                            fig.add_trace(go.Scatter(
                                x=proj[:, 0].tolist(),
                                y=proj[:, 1].tolist(),
                                mode="markers",
                                marker=dict(
                                    color=list(range(p_val)),
                                    colorscale="HSV",
                                    size=6,
                                    opacity=0.9
                                ),
                                showlegend=False
                            ), row=1, col=1)

                            # 10x10ç›¸é–¢è¡Œåˆ—
                            for i in range(grid_size):
                                for j in range(grid_size):
                                    fig.add_trace(go.Scatter(
                                        x=pooled[:, j].tolist(),
                                        y=pooled[:, i].tolist(),
                                        mode="markers",
                                        marker=dict(
                                            color=list(range(len(pooled))),
                                            colorscale="Plasma",
                                            size=3,
                                            opacity=0.6
                                        ),
                                        showlegend=False
                                    ), row=i+1, col=j+2)

                            # å­¦ç¿’æ›²ç·š
                            fig.add_trace(go.Scatter(
                                x=epochs_list, y=train_acc,
                                mode="lines", line=dict(color="#2196F3", width=1.5),
                                name="Train", showlegend=True
                            ), row=grid_size+1, col=1)
                            fig.add_trace(go.Scatter(
                                x=epochs_list, y=test_acc,
                                mode="lines", line=dict(color="#F44336", width=1.5),
                                name="Test", showlegend=True
                            ), row=grid_size+1, col=1)

                            # ç¾åœ¨ä½ç½®ã®ç¸¦ç·š
                            fig.add_trace(go.Scatter(
                                x=[first_ep, first_ep], y=[0, 100],
                                mode="lines", line=dict(color="#FFFF00", width=2),
                                showlegend=False
                            ), row=grid_size+1, col=1)

                        # åˆæœŸangle correlation
                        first_angle_corr = first_data.get("angle_corr", 0) if first_data else 0

                        # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
                        fig.update_layout(
                            height=900,
                            plot_bgcolor="black",
                            paper_bgcolor="black",
                            font=dict(color="white"),
                            margin=dict(t=40, b=70, l=15, r=15),
                            annotations=[dict(
                                text=f"Epoch {first_ep} | Train: {train_acc[min(first_ep-1, len(train_acc)-1)]:.1f}% | Test: {test_acc[min(first_ep-1, len(test_acc)-1)]:.1f}% | Circle: {first_angle_corr:.2f}",
                                xref="paper", yref="paper",
                                x=0.5, y=1.02, showarrow=False,
                                font=dict(size=14, color="white")
                            )],
                            legend=dict(orientation="h", y=-0.12, x=0.5, xanchor="center"),
                            updatemenus=[{
                                "type": "buttons",
                                "showactive": False,
                                "y": -0.15,
                                "x": 0.05,
                                "buttons": [
                                    {"label": "â–¶ å†ç”Ÿ", "method": "animate", "args": [None, {
                                        "frame": {"duration": 100, "redraw": False},
                                        "transition": {"duration": 50, "easing": "linear"},
                                        "fromcurrent": True,
                                        "mode": "immediate"
                                    }]},
                                    {"label": "â¸ åœæ­¢", "method": "animate", "args": [[None], {"frame": {"duration": 0, "redraw": False}, "mode": "immediate"}]}
                                ]
                            }],
                            sliders=[{
                                "active": 0,
                                "steps": slider_steps,
                                "x": 0.2,
                                "len": 0.75,
                                "y": -0.08,
                                "currentvalue": {"prefix": "Epoch: ", "visible": True, "xanchor": "center"},
                                "transition": {"duration": 50, "easing": "linear"}
                            }]
                        )

                        # è»¸è¨­å®šï¼ˆå›ºå®šç¯„å›²ã§æ»‘ã‚‰ã‹ãªã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
                        fig.update_xaxes(showticklabels=False, showgrid=False)
                        fig.update_yaxes(showticklabels=False, showgrid=False)

                        # å††ç’°ãƒ—ãƒ­ãƒƒãƒˆã®è»¸ã‚’å›ºå®š
                        fig.update_xaxes(range=proj_x_range, row=1, col=1)
                        fig.update_yaxes(range=proj_y_range, row=1, col=1)

                        # ç›¸é–¢è¡Œåˆ—ã®è»¸ã‚’å›ºå®š
                        for i in range(grid_size):
                            for j in range(grid_size):
                                fig.update_xaxes(range=pooled_ranges[j], row=i+1, col=j+2)
                                fig.update_yaxes(range=pooled_ranges[i], row=i+1, col=j+2)

                        # å­¦ç¿’æ›²ç·šã®è»¸ã¯è¡¨ç¤º
                        last_row_idx = grid_size + 1
                        fig.update_xaxes(showticklabels=True, showgrid=True, gridcolor="rgba(255,255,255,0.1)",
                                        title_text="Epoch", row=last_row_idx, col=1)
                        fig.update_yaxes(showticklabels=True, showgrid=True, gridcolor="rgba(255,255,255,0.1)",
                                        title_text="Acc%", range=[0, 105], row=last_row_idx, col=1)

                        fig.frames = frames

                        # ã‚°ãƒ©ãƒ•è¡¨ç¤º
                        st.plotly_chart(fig, use_container_width=True)
                    else:
                        st.warning("ã‚¨ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                else:
                    st.warning("ã‚¨ãƒãƒƒã‚¯ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            else:
                st.warning("ã‚¨ãƒãƒƒã‚¯ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        else:
            st.warning("history.json ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

    # ===== Tab 6: Fourier Theory =====
    with tab6:
        st.header("ğŸ“ Fourier Theory")
        st.markdown("""
        **Grokkingã®æ ¸å¿ƒ**: Transformerã¯ãƒ¢ã‚¸ãƒ¥ãƒ©åŠ ç®—ã‚’ãƒ•ãƒ¼ãƒªã‚¨åŸºåº•ã§å­¦ç¿’ã—ã¾ã™ã€‚

        $$\\cos(\\omega(a+b)) = \\cos(\\omega a)\\cos(\\omega b) - \\sin(\\omega a)\\sin(\\omega b)$$
        """)

        p = config["p"]

        # å‘¨æ³¢æ•°é¸æŠ
        col1, col2 = st.columns([1, 3])
        with col1:
            freq_k = st.slider("å‘¨æ³¢æ•° k", 1, min(p // 4, 20), 8, key="theory_freq_k")

        omega = 2 * np.pi * freq_k / p

        # --- ã‚»ã‚¯ã‚·ãƒ§ãƒ³1: è¨ˆç®—ãƒ•ãƒ­ãƒ¼ ---
        st.subheader("1ï¸âƒ£ è¨ˆç®—ãƒ•ãƒ­ãƒ¼ï¼ˆStep by Stepï¼‰")

        col_a, col_b = st.columns(2)
        with col_a:
            a_val = st.number_input("a", 0, p - 1, 15, key="theory_a")
        with col_b:
            b_val = st.number_input("b", 0, p - 1, 25, key="theory_b")

        # è¨ˆç®—
        cos_a = np.cos(omega * a_val)
        sin_a = np.sin(omega * a_val)
        cos_b = np.cos(omega * b_val)
        sin_b = np.sin(omega * b_val)
        cos_cos = cos_a * cos_b
        sin_sin = sin_a * sin_b
        result_fourier = cos_cos - sin_sin
        result_direct = np.cos(omega * (a_val + b_val))
        answer = (a_val + b_val) % p

        # ãƒ•ãƒ­ãƒ¼å›³
        flow_fig = go.Figure()

        # ã‚¹ãƒ†ãƒƒãƒ—é…ç½®
        steps = [
            {"x": 0, "text": f"å…¥åŠ›<br>a={a_val}, b={b_val}", "color": "#667EEA"},
            {"x": 1, "text": f"åŸ‹ã‚è¾¼ã¿<br>cos(Ï‰a)={cos_a:.3f}<br>sin(Ï‰a)={sin_a:.3f}<br>cos(Ï‰b)={cos_b:.3f}<br>sin(Ï‰b)={sin_b:.3f}", "color": "#FFD700"},
            {"x": 2, "text": f"Attention<br>cosÂ·cos={cos_cos:.3f}<br>sinÂ·sin={sin_sin:.3f}", "color": "#FFA500"},
            {"x": 3, "text": f"MLP<br>cosÂ·cos - sinÂ·sin<br>={result_fourier:.3f}", "color": "#4ECDC4"},
            {"x": 4, "text": f"å‡ºåŠ›<br>({a_val}+{b_val}) mod {p}<br>= {answer}", "color": "#FF6B6B"},
        ]

        for i, step in enumerate(steps):
            flow_fig.add_trace(go.Scatter(
                x=[step["x"]], y=[0],
                mode="markers+text",
                marker=dict(size=80, color=step["color"], symbol="square"),
                text=step["text"],
                textposition="middle center",
                textfont=dict(size=10, color="white"),
                showlegend=False
            ))
            if i < len(steps) - 1:
                flow_fig.add_annotation(
                    x=step["x"] + 0.5, y=0,
                    ax=step["x"] + 0.3, ay=0,
                    xref="x", yref="y", axref="x", ayref="y",
                    showarrow=True, arrowhead=2, arrowsize=1.5, arrowcolor="white"
                )

        flow_fig.update_layout(
            title=f"è¨ˆç®—ãƒ•ãƒ­ãƒ¼: ({a_val} + {b_val}) mod {p} = {answer}",
            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False, range=[-0.5, 4.5]),
            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False, range=[-1, 1]),
            height=250,
            paper_bgcolor="rgba(0,0,0,0)",
            plot_bgcolor="rgba(0,0,0,0)",
            font=dict(color="white")
        )
        st.plotly_chart(flow_fig, use_container_width=True, key="flow_chart")

        # æ¤œè¨¼
        st.success(f"âœ… åŠ æ³•å®šç†ã®æ¤œè¨¼: cos(Ï‰({a_val}+{b_val})) = {result_direct:.6f}, cosÂ·cos - sinÂ·sin = {result_fourier:.6f}, å·® = {abs(result_direct - result_fourier):.2e}")

        # --- ã‚»ã‚¯ã‚·ãƒ§ãƒ³2: 3Dè¡¨é¢æ¯”è¼ƒ ---
        st.subheader("2ï¸âƒ£ 3Dè¡¨é¢: cosÂ·cos, sinÂ·sin, cos(x+y)")

        # è»½é‡åŒ–: ã‚°ãƒªãƒƒãƒ‰ã‚µã‚¤ã‚ºã‚’åˆ¶é™
        grid_size = min(30, p)
        X, Y = np.meshgrid(np.arange(grid_size), np.arange(grid_size))
        Z_coscos = np.cos(omega * X) * np.cos(omega * Y)
        Z_sinsin = np.sin(omega * X) * np.sin(omega * Y)
        Z_sum = np.cos(omega * (X + Y))

        surface_col1, surface_col2, surface_col3 = st.columns(3)

        with surface_col1:
            fig1 = go.Figure(data=[go.Surface(z=Z_coscos, x=X, y=Y, colorscale="YlOrBr", showscale=False)])
            fig1.update_layout(
                title="cos(Ï‰x)Â·cos(Ï‰y)",
                scene=dict(xaxis_title="x", yaxis_title="y", zaxis_title=""),
                height=300, margin=dict(l=0, r=0, t=30, b=0)
            )
            st.plotly_chart(fig1, use_container_width=True, key="surface_coscos")

        with surface_col2:
            fig2 = go.Figure(data=[go.Surface(z=Z_sinsin, x=X, y=Y, colorscale="Oranges", showscale=False)])
            fig2.update_layout(
                title="sin(Ï‰x)Â·sin(Ï‰y)",
                scene=dict(xaxis_title="x", yaxis_title="y", zaxis_title=""),
                height=300, margin=dict(l=0, r=0, t=30, b=0)
            )
            st.plotly_chart(fig2, use_container_width=True, key="surface_sinsin")

        with surface_col3:
            fig3 = go.Figure(data=[go.Surface(z=Z_sum, x=X, y=Y, colorscale="Teal", showscale=False)])
            fig3.update_layout(
                title="cos(Ï‰(x+y)) = cosÂ·cos - sinÂ·sin",
                scene=dict(xaxis_title="x", yaxis_title="y", zaxis_title=""),
                height=300, margin=dict(l=0, r=0, t=30, b=0)
            )
            st.plotly_chart(fig3, use_container_width=True, key="surface_sum")

        # --- ã‚»ã‚¯ã‚·ãƒ§ãƒ³3: ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³æ³¢å½¢æ¯”è¼ƒ ---
        st.subheader("3ï¸âƒ£ ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³æ³¢å½¢ vs ç†è«–çš„cos/sin")

        x_vals = np.arange(p)

        # å®Ÿéš›ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³å‡ºåŠ›ã‚’å–å¾—
        try:
            n_tokens = config.get("n_tokens", 2)
            if n_tokens == 2:
                inputs = torch.tensor([[x, 0] for x in range(p)])
            else:
                inputs = torch.tensor([[x, 0, 0] for x in range(p)])

            with torch.no_grad():
                _, intermediates = model.forward_with_intermediates(inputs)
            pooled = intermediates["pooled"].numpy()

            # å„æ¬¡å…ƒã®cos/sinç›¸é–¢ã‚’è¨ˆç®—ï¼ˆé«˜é€Ÿç‰ˆï¼‰
            s_values = np.arange(p)
            cos_basis = np.cos(omega * s_values)
            sin_basis = np.sin(omega * s_values)

            best_cos_dim, best_cos_corr = 0, 0
            best_sin_dim, best_sin_corr = 0, 0

            for d in range(pooled.shape[1]):
                dim_vals = pooled[:, d]
                if np.std(dim_vals) > 0.01:
                    cc = abs(np.corrcoef(dim_vals, cos_basis)[0, 1])
                    sc = abs(np.corrcoef(dim_vals, sin_basis)[0, 1])
                    if not np.isnan(cc) and cc > best_cos_corr:
                        best_cos_corr = cc
                        best_cos_dim = d
                    if not np.isnan(sc) and sc > best_sin_corr:
                        best_sin_corr = sc
                        best_sin_dim = d

            # æ­£è¦åŒ–
            cos_neuron = pooled[:, best_cos_dim]
            sin_neuron = pooled[:, best_sin_dim]
            cos_neuron_norm = (cos_neuron - cos_neuron.mean()) / (cos_neuron.std() + 1e-8)
            sin_neuron_norm = (sin_neuron - sin_neuron.mean()) / (sin_neuron.std() + 1e-8)

            wave_fig = make_subplots(rows=1, cols=2, subplot_titles=[
                f"Cosæ¬¡å…ƒ d{best_cos_dim} (corr={best_cos_corr:.3f})",
                f"Sinæ¬¡å…ƒ d{best_sin_dim} (corr={best_sin_corr:.3f})"
            ])

            # Cosæ¯”è¼ƒ
            wave_fig.add_trace(go.Scatter(x=x_vals, y=cos_neuron_norm, mode="lines", name="ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³å‡ºåŠ›", line=dict(color="#FFD700")), row=1, col=1)
            wave_fig.add_trace(go.Scatter(x=x_vals, y=cos_basis, mode="lines", name=f"cos(2Ï€Â·{freq_k}Â·x/{p})", line=dict(color="#4ECDC4", dash="dash")), row=1, col=1)

            # Sinæ¯”è¼ƒ
            wave_fig.add_trace(go.Scatter(x=x_vals, y=sin_neuron_norm, mode="lines", name="ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³å‡ºåŠ›", line=dict(color="#FF69B4")), row=1, col=2)
            wave_fig.add_trace(go.Scatter(x=x_vals, y=sin_basis, mode="lines", name=f"sin(2Ï€Â·{freq_k}Â·x/{p})", line=dict(color="#4ECDC4", dash="dash")), row=1, col=2)

            wave_fig.update_layout(height=300, showlegend=True)
            st.plotly_chart(wave_fig, use_container_width=True, key="wave_comparison")

            # --- ã‚»ã‚¯ã‚·ãƒ§ãƒ³4: ãƒªã‚µãƒ¼ã‚¸ãƒ¥å›³å½¢ ---
            st.subheader("4ï¸âƒ£ ãƒªã‚µãƒ¼ã‚¸ãƒ¥å›³å½¢ï¼ˆcos vs sin ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ï¼‰")

            lissajous_fig = go.Figure()
            lissajous_fig.add_trace(go.Scatter(
                x=cos_neuron_norm, y=sin_neuron_norm,
                mode="markers",
                marker=dict(size=8, color=x_vals, colorscale="Rainbow", showscale=True, colorbar=dict(title="x")),
                text=[f"x={x}" for x in x_vals],
                hovertemplate="x=%{text}<br>cos_dim=%{x:.3f}<br>sin_dim=%{y:.3f}<extra></extra>"
            ))
            lissajous_fig.update_layout(
                title=f"ãƒªã‚µãƒ¼ã‚¸ãƒ¥: d{best_cos_dim} vs d{best_sin_dim}ï¼ˆå††å½¢ãªã‚‰å‘¨æ³¢æ•°{freq_k}ã‚’å­¦ç¿’æ¸ˆã¿ï¼‰",
                xaxis_title=f"æ¬¡å…ƒ {best_cos_dim} (cosç›¸é–¢)",
                yaxis_title=f"æ¬¡å…ƒ {best_sin_dim} (sinç›¸é–¢)",
                height=400,
                xaxis=dict(scaleanchor="y", scaleratio=1)
            )
            st.plotly_chart(lissajous_fig, use_container_width=True, key="lissajous")

        except Exception as e:
            st.error(f"ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³è§£æã‚¨ãƒ©ãƒ¼: {e}")

        # --- ã‚»ã‚¯ã‚·ãƒ§ãƒ³5: åŠ æ³•å®šç†æ¤œè¨¼ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆ ---
        st.subheader("5ï¸âƒ£ åŠ æ³•å®šç†ã®æ¤œè¨¼ï¼ˆãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆï¼‰")

        terms = ["cos(Ï‰a)", "cos(Ï‰b)", "sin(Ï‰a)", "sin(Ï‰b)", "cosÂ·cos", "sinÂ·sin", "LHS", "RHS"]
        values = [cos_a, cos_b, sin_a, sin_b, cos_cos, sin_sin, result_direct, result_fourier]
        colors = ["#667EEA", "#667EEA", "#F5576C", "#F5576C", "#FFD700", "#FFA500", "#4ECDC4", "#4ECDC4"]

        bar_fig = go.Figure(data=[go.Bar(x=terms, y=values, marker_color=colors, text=[f"{v:.3f}" for v in values], textposition="outside")])
        bar_fig.update_layout(
            title=f"åŠ æ³•å®šç†: a={a_val}, b={b_val}, k={freq_k}",
            yaxis_title="å€¤",
            height=350,
            yaxis=dict(range=[min(values) - 0.3, max(values) + 0.3])
        )
        st.plotly_chart(bar_fig, use_container_width=True, key="addition_theorem_bar")

    # ===== Tab 7: Attention Analysis =====
    with tab7:
        st.header("ğŸ” Attention Analysis")

        # è§£èª¬
        with st.expander("ğŸ“š Attentionæ©Ÿæ§‹ã®å½¹å‰²", expanded=False):
            st.markdown("""
            **Attentionæ©Ÿæ§‹** ã¯ã€Transformerã®ä¸­æ ¸ã§ã‚ã‚Šã€Grokkingã«ãŠã„ã¦é‡è¦ãªå½¹å‰²ã‚’æœãŸã—ã¾ã™ã€‚

            ### Attentionã®åƒã
            å…¥åŠ› `[a, b]` ã«å¯¾ã—ã¦ã€Attentionã¯ä»¥ä¸‹ã‚’è¡Œã„ã¾ã™ï¼š

            1. **Query, Key, Value ã®è¨ˆç®—**: å„ãƒˆãƒ¼ã‚¯ãƒ³ã®åŸ‹ã‚è¾¼ã¿ã‹ã‚‰ Q, K, V ã‚’ç”Ÿæˆ
            2. **Attentioné‡ã¿**: `softmax(QÂ·K^T / âˆšd)` ã§è¨ˆç®—
            3. **å€¤ã®é›†ç´„**: é‡ã¿ã§ V ã‚’é‡ã¿ä»˜ã‘å¹³å‡

            ### Grokkingã§ã®å½¹å‰²
            - **åŸ‹ã‚è¾¼ã¿ã®æ›ã‘ç®—**: cos(Ï‰a)Â·cos(Ï‰b) ã‚„ sin(Ï‰a)Â·sin(Ï‰b) ã‚’è¨ˆç®—
            - **æƒ…å ±ã®çµ±åˆ**: a ã¨ b ã®æƒ…å ±ã‚’çµ±åˆ
            - **ãƒ•ãƒ¼ãƒªã‚¨æˆåˆ†ã®æ··åˆ**: åŠ æ³•å®šç†ã®å‰åŠéƒ¨åˆ†ã‚’æ‹…å½“

            ### Attentionãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ„å‘³
            - **Attn[aâ†’b]**: aãŒbã®æƒ…å ±ã‚’ã©ã‚Œã ã‘å–ã‚Šè¾¼ã‚€ã‹
            - **Attn[bâ†’a]**: bãŒaã®æƒ…å ±ã‚’ã©ã‚Œã ã‘å–ã‚Šè¾¼ã‚€ã‹
            """)

        p = config["p"]
        n_tokens = config.get("n_tokens", 2)
        n_heads = config.get("n_heads", 4)

        try:
            # ===== 1. å…¨ä½“Attentionãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒ— =====
            st.subheader("1ï¸âƒ£ å…¨ä½“Attentionãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒ—")
            st.markdown("å…¨ã¦ã®(a, b)ãƒšã‚¢ã«å¯¾ã™ã‚‹Attentioné‡ã¿ã‚’å¯è¦–åŒ–")

            # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ•°
            sample_step = max(1, p // 30)  # æœ€å¤§30x30ã®ã‚°ãƒªãƒƒãƒ‰

            @st.cache_data
            def compute_attention_maps(_model_id, _p, _n_tokens, _sample_step):
                """å…¨(a,b)ãƒšã‚¢ã®Attentioné‡ã¿ã‚’è¨ˆç®—"""
                a_vals = list(range(0, p, _sample_step))
                b_vals = list(range(0, p, _sample_step))
                n_a, n_b = len(a_vals), len(b_vals)

                # ãƒãƒƒãƒã§è¨ˆç®—
                inputs = []
                for a in a_vals:
                    for b in b_vals:
                        if _n_tokens == 2:
                            inputs.append([a, b])
                        else:
                            inputs.append([a, b, 0])

                inputs_tensor = torch.tensor(inputs)
                with torch.no_grad():
                    _, intermediates = model.forward_with_intermediates(inputs_tensor)

                attn_weights = intermediates["block_0_attn_weights"]  # (batch, heads, seq, seq)
                return attn_weights.numpy(), a_vals, b_vals

            # Attentioné‡ã¿ã‚’è¨ˆç®—
            all_attn, a_vals, b_vals = compute_attention_maps(
                id(model), p, n_tokens, sample_step
            )
            n_a, n_b = len(a_vals), len(b_vals)

            # ãƒ˜ãƒƒãƒ‰ã¨Attentionãƒ‘ã‚¿ãƒ¼ãƒ³ã®é¸æŠ
            col_head, col_pattern = st.columns(2)
            with col_head:
                head_select = st.selectbox(
                    "ãƒ˜ãƒƒãƒ‰é¸æŠ",
                    ["å…¨ãƒ˜ãƒƒãƒ‰å¹³å‡"] + [f"Head {i}" for i in range(all_attn.shape[1])],
                    key="attn_map_head"
                )
            with col_pattern:
                pattern_select = st.selectbox(
                    "Attentionãƒ‘ã‚¿ãƒ¼ãƒ³",
                    ["aâ†’b (aãŒbã‚’è¦‹ã‚‹)", "bâ†’a (bãŒaã‚’è¦‹ã‚‹)", "aâ†’a (è‡ªå·±æ³¨æ„)", "bâ†’b (è‡ªå·±æ³¨æ„)"],
                    key="attn_pattern"
                )

            # ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¿œã˜ãŸã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
            pattern_map = {
                "aâ†’b (aãŒbã‚’è¦‹ã‚‹)": (0, 1),
                "bâ†’a (bãŒaã‚’è¦‹ã‚‹)": (1, 0),
                "aâ†’a (è‡ªå·±æ³¨æ„)": (0, 0),
                "bâ†’b (è‡ªå·±æ³¨æ„)": (1, 1),
            }
            qi, ki = pattern_map[pattern_select]

            # ãƒ˜ãƒƒãƒ‰ã®é¸æŠ
            if head_select == "å…¨ãƒ˜ãƒƒãƒ‰å¹³å‡":
                attn_slice = all_attn.mean(axis=1)[:, qi, ki]
            else:
                head_idx = int(head_select.split()[-1])
                attn_slice = all_attn[:, head_idx, qi, ki]

            # 2Dãƒãƒƒãƒ—ã«æ•´å½¢
            attn_map = attn_slice.reshape(n_a, n_b)

            fig_map = go.Figure(data=go.Heatmap(
                z=attn_map,
                x=b_vals,
                y=a_vals,
                colorscale="RdBu",
                zmid=0.5,
                colorbar=dict(title="Attention")
            ))
            fig_map.update_layout(
                title=f"{pattern_select} - {head_select}",
                xaxis_title="b",
                yaxis_title="a",
                height=500,
                width=600
            )
            st.plotly_chart(fig_map, use_container_width=True, key="attn_full_map")

            # ===== 2. ãƒ˜ãƒƒãƒ‰åˆ¥Attentionãƒ‘ã‚¿ãƒ¼ãƒ³æ¯”è¼ƒ =====
            st.subheader("2ï¸âƒ£ å…¨ãƒ˜ãƒƒãƒ‰ã®Attentionãƒ‘ã‚¿ãƒ¼ãƒ³æ¯”è¼ƒ")
            st.markdown("å„ãƒ˜ãƒƒãƒ‰ãŒã©ã®ã‚ˆã†ãªå½¹å‰²ã‚’æŒã£ã¦ã„ã‚‹ã‹ã‚’æ¯”è¼ƒ")

            n_heads_actual = all_attn.shape[1]
            cols = st.columns(n_heads_actual)

            for h in range(n_heads_actual):
                with cols[h]:
                    # aâ†’b ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¡¨ç¤º
                    attn_h = all_attn[:, h, 0, 1].reshape(n_a, n_b)
                    fig_h = go.Figure(data=go.Heatmap(
                        z=attn_h,
                        colorscale="Viridis",
                        showscale=False
                    ))
                    fig_h.update_layout(
                        title=f"Head {h}",
                        height=200,
                        margin=dict(l=10, r=10, t=40, b=10),
                        xaxis=dict(showticklabels=False, title="b"),
                        yaxis=dict(showticklabels=False, title="a")
                    )
                    st.plotly_chart(fig_h, use_container_width=True, key=f"attn_head_map_{h}")

                    # çµ±è¨ˆæƒ…å ±
                    mean_val = attn_h.mean()
                    std_val = attn_h.std()
                    st.caption(f"mean={mean_val:.3f}, std={std_val:.3f}")

            # ===== 3. Attentioné‡ã¿åˆ†å¸ƒ =====
            st.subheader("3ï¸âƒ£ Attentioné‡ã¿åˆ†å¸ƒ")

            col1, col2 = st.columns(2)

            with col1:
                # å…¨ã‚µãƒ³ãƒ—ãƒ«ã®åˆ†å¸ƒ
                fig_hist = go.Figure()
                for h in range(n_heads_actual):
                    attn_flat = all_attn[:, h, 0, 1].flatten()
                    fig_hist.add_trace(go.Histogram(
                        x=attn_flat,
                        name=f"Head {h}",
                        opacity=0.6,
                        nbinsx=30
                    ))
                fig_hist.update_layout(
                    title="Attention[aâ†’b]ã®åˆ†å¸ƒï¼ˆå…¨ã‚µãƒ³ãƒ—ãƒ«ï¼‰",
                    xaxis_title="Attention Weight",
                    yaxis_title="Count",
                    barmode="overlay",
                    height=350
                )
                st.plotly_chart(fig_hist, use_container_width=True, key="attn_hist")

            with col2:
                # ãƒ˜ãƒƒãƒ‰é–“ã®ç›¸é–¢
                head_patterns = []
                for h in range(n_heads_actual):
                    head_patterns.append(all_attn[:, h, 0, 1].flatten())
                head_patterns = np.array(head_patterns)

                corr_matrix = np.corrcoef(head_patterns)
                fig_corr = go.Figure(data=go.Heatmap(
                    z=corr_matrix,
                    x=[f"H{i}" for i in range(n_heads_actual)],
                    y=[f"H{i}" for i in range(n_heads_actual)],
                    colorscale="RdBu",
                    zmid=0,
                    text=[[f"{v:.2f}" for v in row] for row in corr_matrix],
                    texttemplate="%{text}"
                ))
                fig_corr.update_layout(
                    title="ãƒ˜ãƒƒãƒ‰é–“ã®ç›¸é–¢",
                    height=350
                )
                st.plotly_chart(fig_corr, use_container_width=True, key="head_corr")

            # ===== 4. å€‹åˆ¥ã‚µãƒ³ãƒ—ãƒ«åˆ†æ =====
            st.subheader("4ï¸âƒ£ å€‹åˆ¥ã‚µãƒ³ãƒ—ãƒ«åˆ†æ")

            col_a, col_b = st.columns(2)
            with col_a:
                a_att = st.slider("a", 0, p - 1, 10, key="attn_a")
            with col_b:
                b_att = st.slider("b", 0, p - 1, 20, key="attn_b")

            answer = (a_att + b_att) % p
            st.info(f"å…¥åŠ›: ({a_att}, {b_att}) â†’ æ­£è§£: ({a_att} + {b_att}) mod {p} = {answer}")

            # å˜ä¸€ã‚µãƒ³ãƒ—ãƒ«ã®Attention
            if n_tokens == 2:
                test_input = torch.tensor([[a_att, b_att]])
            else:
                test_input = torch.tensor([[a_att, b_att, 0]])

            with torch.no_grad():
                logits, intermediates = model.forward_with_intermediates(test_input)

            pred = logits.argmax(dim=-1).item()
            pred_correct = "âœ…" if pred == answer else "âŒ"
            st.success(f"äºˆæ¸¬: {pred} {pred_correct}")

            attn_weights = intermediates["block_0_attn_weights"]
            n_heads_single = attn_weights.shape[1]

            # å…¨ãƒ˜ãƒƒãƒ‰ã‚’æ¨ªã«ä¸¦ã¹ã¦è¡¨ç¤º
            cols = st.columns(n_heads_single + 1)

            if n_tokens == 2:
                labels = ["a", "b"]
            else:
                labels = ["a", "b", "="]

            for h in range(n_heads_single):
                with cols[h]:
                    attn_h = attn_weights[0, h].numpy()
                    if attn_h.ndim == 1:
                        s = int(np.sqrt(len(attn_h)))
                        attn_h = attn_h.reshape(s, s)

                    text_h = [[f"{attn_h[i, j]:.2f}" for j in range(attn_h.shape[1])]
                             for i in range(attn_h.shape[0])]

                    fig_h = go.Figure(data=go.Heatmap(
                        z=attn_h.tolist(),
                        x=labels,
                        y=labels,
                        colorscale="Viridis",
                        text=text_h,
                        texttemplate="%{text}",
                        showscale=False
                    ))
                    fig_h.update_layout(
                        title=f"Head {h}",
                        height=250,
                        margin=dict(l=30, r=10, t=40, b=30),
                    )
                    st.plotly_chart(fig_h, use_container_width=True, key=f"single_head_{h}")

            # å¹³å‡Attention
            with cols[-1]:
                avg_attn = attn_weights[0].mean(dim=0).numpy()
                if avg_attn.ndim == 1:
                    s = int(np.sqrt(len(avg_attn)))
                    avg_attn = avg_attn.reshape(s, s)

                avg_text = [[f"{avg_attn[i, j]:.2f}" for j in range(avg_attn.shape[1])]
                           for i in range(avg_attn.shape[0])]

                fig_avg = go.Figure(data=go.Heatmap(
                    z=avg_attn.tolist(),
                    x=labels,
                    y=labels,
                    colorscale="Viridis",
                    text=avg_text,
                    texttemplate="%{text}",
                    showscale=False
                ))
                fig_avg.update_layout(
                    title="å¹³å‡",
                    height=250,
                    margin=dict(l=30, r=10, t=40, b=30),
                )
                st.plotly_chart(fig_avg, use_container_width=True, key="single_avg")

            # ===== 5. aã¾ãŸã¯bã‚’å›ºå®šã—ãŸæ™‚ã®Attentionå¤‰åŒ– =====
            st.subheader("5ï¸âƒ£ å…¥åŠ›å€¤ã«ã‚ˆã‚‹Attentionå¤‰åŒ–")

            col1, col2 = st.columns(2)

            with col1:
                st.markdown("**aã‚’å›ºå®šã€bã‚’å¤‰åŒ–**")
                fixed_a = st.slider("å›ºå®šã™ã‚‹aã®å€¤", 0, p - 1, 0, key="fixed_a")

                # bã‚’å¤‰åŒ–ã•ã›ã¦Attentionã‚’è¨ˆç®—
                b_range = list(range(0, p, max(1, p // 50)))
                attn_by_b = []

                inputs_b = torch.tensor([[fixed_a, b] for b in b_range])
                with torch.no_grad():
                    _, inter_b = model.forward_with_intermediates(inputs_b)
                attn_b = inter_b["block_0_attn_weights"].numpy()

                fig_by_b = go.Figure()
                for h in range(attn_b.shape[1]):
                    fig_by_b.add_trace(go.Scatter(
                        x=b_range,
                        y=attn_b[:, h, 0, 1],
                        name=f"Head {h}",
                        mode="lines+markers"
                    ))
                fig_by_b.update_layout(
                    title=f"a={fixed_a}å›ºå®šã€bã‚’å¤‰åŒ–ã•ã›ãŸæ™‚ã®Attn[aâ†’b]",
                    xaxis_title="b",
                    yaxis_title="Attention[aâ†’b]",
                    height=300
                )
                st.plotly_chart(fig_by_b, use_container_width=True, key="attn_by_b")

            with col2:
                st.markdown("**bã‚’å›ºå®šã€aã‚’å¤‰åŒ–**")
                fixed_b = st.slider("å›ºå®šã™ã‚‹bã®å€¤", 0, p - 1, 0, key="fixed_b")

                # aã‚’å¤‰åŒ–ã•ã›ã¦Attentionã‚’è¨ˆç®—
                a_range = list(range(0, p, max(1, p // 50)))

                inputs_a = torch.tensor([[a, fixed_b] for a in a_range])
                with torch.no_grad():
                    _, inter_a = model.forward_with_intermediates(inputs_a)
                attn_a = inter_a["block_0_attn_weights"].numpy()

                fig_by_a = go.Figure()
                for h in range(attn_a.shape[1]):
                    fig_by_a.add_trace(go.Scatter(
                        x=a_range,
                        y=attn_a[:, h, 0, 1],
                        name=f"Head {h}",
                        mode="lines+markers"
                    ))
                fig_by_a.update_layout(
                    title=f"b={fixed_b}å›ºå®šã€aã‚’å¤‰åŒ–ã•ã›ãŸæ™‚ã®Attn[aâ†’b]",
                    xaxis_title="a",
                    yaxis_title="Attention[aâ†’b]",
                    height=300
                )
                st.plotly_chart(fig_by_a, use_container_width=True, key="attn_by_a")

            # ===== 6. åŸ‹ã‚è¾¼ã¿ã®å¯è¦–åŒ– =====
            st.subheader("6ï¸âƒ£ å…¥åŠ›åŸ‹ã‚è¾¼ã¿")
            embed_key = "embed"
            if embed_key in intermediates:
                embeddings = intermediates[embed_key][0].numpy()

                n_dims_show = min(32, embeddings.shape[1])
                fig_emb = go.Figure()
                for i, label in enumerate(labels):
                    fig_emb.add_trace(go.Bar(
                        name=label,
                        x=[f"d{j}" for j in range(n_dims_show)],
                        y=embeddings[i, :n_dims_show],
                    ))
                fig_emb.update_layout(
                    title=f"å…¥åŠ›åŸ‹ã‚è¾¼ã¿ï¼ˆæœ€åˆã®{n_dims_show}æ¬¡å…ƒï¼‰",
                    barmode="group",
                    height=300
                )
                st.plotly_chart(fig_emb, use_container_width=True, key="embeddings_bar")

        except Exception as e:
            st.error(f"Attentionè§£æã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            st.code(traceback.format_exc())

    # ===== Tab 8: Neuron Analysis =====
    with tab8:
        st.header("ğŸ§  MLP Neuron Analysis")

        with st.expander("ğŸ“š MLPãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®å½¹å‰²", expanded=False):
            st.markdown("""
            **MLP (Multi-Layer Perceptron)** ã¯Transformerã®å„ãƒ–ãƒ­ãƒƒã‚¯å†…ã«ã‚ã‚Šã€
            Grokkingã«ãŠã„ã¦**åŠ æ³•å®šç†ã®è¨ˆç®—**ã‚’æ‹…å½“ã—ã¾ã™ã€‚

            ### MLPã®æ§‹é€ 
            ```
            å…¥åŠ› â†’ Linear(d_model â†’ d_ff) â†’ GELU â†’ Linear(d_ff â†’ d_model) â†’ å‡ºåŠ›
            ```

            ### Grokkingã§ã®å½¹å‰²
            - **cosÂ·cos ã¨ sinÂ·sin ã®æ›ã‘ç®—**: Attentionå¾Œã®è¡¨ç¾ã‚’å‡¦ç†
            - **å¼•ãç®—**: cos(Ï‰(a+b)) = cosÂ·cos - sinÂ·sin ã‚’è¨ˆç®—
            - **å‘¨æ³¢æ•°ã”ã¨ã®å‡¦ç†**: ç•°ãªã‚‹ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãŒç•°ãªã‚‹å‘¨æ³¢æ•°kã‚’æ‹…å½“

            ### ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®è¦‹æ–¹
            - **æ´»æ€§åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³**: å…¥åŠ›(a,b)ã«å¯¾ã—ã¦ã©ã†åå¿œã™ã‚‹ã‹
            - **å‘¨æ³¢æ•°é¸æŠæ€§**: ç‰¹å®šã®kã«å¯¾å¿œã™ã‚‹cos/sinãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŒã¤ã‹
            - **ãƒ•ãƒ¼ãƒªã‚¨ç›¸é–¢**: ç†è«–çš„ãªcos(2Ï€kn/p)ã¨ã®ç›¸é–¢
            """)

        p = config["p"]
        n_tokens = config.get("n_tokens", 2)
        d_model = config.get("d_model", 128)

        try:
            # MLPã®é‡ã¿ã‚’å–å¾—
            mlp_weights = {}
            for name, param in model.named_parameters():
                if "ff" in name:
                    mlp_weights[name] = param.detach().cpu().numpy()

            st.subheader("1ï¸âƒ£ MLPé‡ã¿ã®æ§‹é€ ")

            # é‡ã¿ã®ãƒªã‚¹ãƒˆè¡¨ç¤º
            weight_info = []
            for name, w in mlp_weights.items():
                weight_info.append({
                    "ãƒ¬ã‚¤ãƒ¤ãƒ¼": name,
                    "å½¢çŠ¶": str(w.shape),
                    "ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°": w.size,
                    "å¹³å‡": f"{w.mean():.4f}",
                    "æ¨™æº–åå·®": f"{w.std():.4f}"
                })
            st.dataframe(pd.DataFrame(weight_info), use_container_width=True)

            # ===== 2. ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³æ´»æ€§åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ =====
            st.subheader("2ï¸âƒ£ ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³æ´»æ€§åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³")
            st.markdown("å„ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãŒå…¥åŠ›(a, b)ã«å¯¾ã—ã¦ã©ã®ã‚ˆã†ã«æ´»æ€§åŒ–ã™ã‚‹ã‹")

            # ã‚µãƒ³ãƒ—ãƒ«å…¥åŠ›ã§æ´»æ€§åŒ–ã‚’è¨ˆç®—
            @st.cache_data
            def compute_neuron_activations(_model_id, _p, _n_tokens):
                """å…¨(a,b)ãƒšã‚¢ã«å¯¾ã™ã‚‹MLPä¸­é–“æ´»æ€§åŒ–ã‚’è¨ˆç®—"""
                sample_step = max(1, _p // 25)
                a_vals = list(range(0, _p, sample_step))
                b_vals = list(range(0, _p, sample_step))

                inputs = []
                for a in a_vals:
                    for b in b_vals:
                        if _n_tokens == 2:
                            inputs.append([a, b])
                        else:
                            inputs.append([a, b, 0])

                inputs_tensor = torch.tensor(inputs)
                with torch.no_grad():
                    _, intermediates = model.forward_with_intermediates(inputs_tensor)

                # MLPä¸­é–“å‡ºåŠ›ï¼ˆGELUå¾Œï¼‰ã‚’å–å¾—
                # block_0_ff_outã¯FFNå…¨ä½“ã®å‡ºåŠ›ãªã®ã§ã€ä¸­é–“å±¤ã‚’ç›´æ¥å–å¾—
                ff_out = intermediates.get("block_0_ff_out", None)
                post_attn = intermediates.get("block_0_post_attn", None)

                return ff_out, post_attn, a_vals, b_vals

            ff_out, post_attn, a_vals, b_vals = compute_neuron_activations(id(model), p, n_tokens)

            if ff_out is not None:
                n_a, n_b = len(a_vals), len(b_vals)

                # ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³é¸æŠ
                n_neurons_show = min(16, ff_out.shape[-1])
                neuron_idx = st.slider("è¡¨ç¤ºã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³é–‹å§‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹", 0, ff_out.shape[-1] - n_neurons_show, 0, key="neuron_start")

                # 4x4ã‚°ãƒªãƒƒãƒ‰ã§è¡¨ç¤º
                cols_per_row = 4
                rows = (n_neurons_show + cols_per_row - 1) // cols_per_row

                for row in range(rows):
                    cols = st.columns(cols_per_row)
                    for col_idx, col in enumerate(cols):
                        n_idx = neuron_idx + row * cols_per_row + col_idx
                        if n_idx < ff_out.shape[-1] and (row * cols_per_row + col_idx) < n_neurons_show:
                            with col:
                                # å¹³å‡poolingå¾Œã®æ´»æ€§åŒ–ã‚’å–å¾—
                                neuron_act = ff_out[:, :, n_idx].mean(dim=1).numpy()  # (batch,)
                                act_map = neuron_act.reshape(n_a, n_b)

                                fig_n = go.Figure(data=go.Heatmap(
                                    z=act_map,
                                    colorscale="RdBu",
                                    zmid=0,
                                    showscale=False
                                ))
                                fig_n.update_layout(
                                    title=f"N{n_idx}",
                                    height=150,
                                    margin=dict(l=5, r=5, t=30, b=5),
                                    xaxis=dict(showticklabels=False),
                                    yaxis=dict(showticklabels=False)
                                )
                                st.plotly_chart(fig_n, use_container_width=True, key=f"neuron_{n_idx}")

            # ===== 3. ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®ãƒ•ãƒ¼ãƒªã‚¨ç›¸é–¢ =====
            st.subheader("3ï¸âƒ£ ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®ãƒ•ãƒ¼ãƒªã‚¨ç›¸é–¢")
            st.markdown("å„ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãŒã©ã®å‘¨æ³¢æ•°kã«å¯¾å¿œã—ã¦ã„ã‚‹ã‹")

            if ff_out is not None:
                # å„ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®å‡ºåŠ›ã¨ãƒ•ãƒ¼ãƒªã‚¨åŸºåº•ã®ç›¸é–¢ã‚’è¨ˆç®—
                @st.cache_data
                def compute_neuron_fourier_correlation(_model_id, _p):
                    """ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³æ´»æ€§åŒ–ã¨ãƒ•ãƒ¼ãƒªã‚¨åŸºåº•ã®ç›¸é–¢"""
                    # å˜ä¸€ãƒˆãƒ¼ã‚¯ãƒ³å…¥åŠ›ã§ã®æ´»æ€§åŒ–
                    inputs = torch.tensor([[n, 0] for n in range(_p)])
                    with torch.no_grad():
                        _, inter = model.forward_with_intermediates(inputs)

                    ff = inter.get("block_0_ff_out", None)
                    if ff is None:
                        return None, None

                    # å„ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®æ´»æ€§åŒ–ï¼ˆæœ€åˆã®ãƒˆãƒ¼ã‚¯ãƒ³ä½ç½®ï¼‰
                    neuron_acts = ff[:, 0, :].numpy()  # (p, n_neurons)
                    n_neurons = neuron_acts.shape[1]

                    # ãƒ•ãƒ¼ãƒªã‚¨ç›¸é–¢è¡Œåˆ—
                    n_freqs = _p // 2
                    corr_matrix = np.zeros((n_neurons, n_freqs))
                    n = np.arange(_p)

                    for k in range(n_freqs):
                        cos_basis = np.cos(2 * np.pi * k * n / _p)
                        sin_basis = np.sin(2 * np.pi * k * n / _p)

                        for ni in range(n_neurons):
                            act = neuron_acts[:, ni]
                            cos_corr = abs(np.corrcoef(act, cos_basis)[0, 1]) if np.std(act) > 1e-6 else 0
                            sin_corr = abs(np.corrcoef(act, sin_basis)[0, 1]) if np.std(act) > 1e-6 else 0
                            corr_matrix[ni, k] = max(cos_corr, sin_corr) if not np.isnan(cos_corr) and not np.isnan(sin_corr) else 0

                    return corr_matrix, neuron_acts

                corr_matrix, neuron_acts = compute_neuron_fourier_correlation(id(model), p)

                if corr_matrix is not None:
                    # ç›¸é–¢ãŒé«˜ã„ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚’æŠ½å‡º
                    max_corrs = corr_matrix.max(axis=1)
                    best_freqs = corr_matrix.argmax(axis=1)
                    top_neurons = np.argsort(max_corrs)[-20:][::-1]

                    col1, col2 = st.columns(2)

                    with col1:
                        # ç›¸é–¢ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆä¸Šä½ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®ã¿ï¼‰
                        fig_corr = go.Figure(data=go.Heatmap(
                            z=corr_matrix[top_neurons, :min(30, p//2)],
                            x=[f"k={k}" for k in range(min(30, p//2))],
                            y=[f"N{n}" for n in top_neurons],
                            colorscale="Viridis"
                        ))
                        fig_corr.update_layout(
                            title="ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³Ã—å‘¨æ³¢æ•° ç›¸é–¢ï¼ˆä¸Šä½20ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ï¼‰",
                            xaxis_title="å‘¨æ³¢æ•° k",
                            yaxis_title="ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³",
                            height=400
                        )
                        st.plotly_chart(fig_corr, use_container_width=True, key="neuron_fourier_corr")

                    with col2:
                        # å‘¨æ³¢æ•°ã”ã¨ã®æœ€å¤§ç›¸é–¢ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³
                        freq_max_corr = corr_matrix.max(axis=0)[:min(30, p//2)]
                        fig_freq = go.Figure(data=go.Bar(
                            x=[f"k={k}" for k in range(len(freq_max_corr))],
                            y=freq_max_corr,
                            marker_color=["#FF5722" if c > 0.7 else "#3F51B5" for c in freq_max_corr]
                        ))
                        fig_freq.update_layout(
                            title="å‘¨æ³¢æ•°ã”ã¨ã®æœ€å¤§ãƒ•ãƒ¼ãƒªã‚¨ç›¸é–¢",
                            xaxis_title="å‘¨æ³¢æ•° k",
                            yaxis_title="æœ€å¤§ç›¸é–¢",
                            height=400
                        )
                        st.plotly_chart(fig_freq, use_container_width=True, key="freq_max_corr")

                    # ä¸Šä½ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®è©³ç´°
                    st.markdown("**ä¸Šä½ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®è©³ç´°:**")
                    neuron_detail = []
                    for ni in top_neurons[:10]:
                        neuron_detail.append({
                            "ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³": f"N{ni}",
                            "æœ€å¤§ç›¸é–¢": f"{max_corrs[ni]:.3f}",
                            "å¯¾å¿œå‘¨æ³¢æ•°": f"k={best_freqs[ni]}",
                            "æ´»æ€§åŒ–å¹³å‡": f"{neuron_acts[:, ni].mean():.3f}",
                            "æ´»æ€§åŒ–std": f"{neuron_acts[:, ni].std():.3f}"
                        })
                    st.dataframe(pd.DataFrame(neuron_detail), use_container_width=True)

            # ===== 4. å€‹åˆ¥ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³æ³¢å½¢ =====
            st.subheader("4ï¸âƒ£ å€‹åˆ¥ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³æ³¢å½¢")

            if neuron_acts is not None:
                n_neurons_total = neuron_acts.shape[1]
                selected_neuron = st.selectbox(
                    "ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚’é¸æŠ",
                    [f"N{i} (k={best_freqs[i]}, corr={max_corrs[i]:.3f})" for i in top_neurons[:20]],
                    key="selected_neuron"
                )
                ni = int(selected_neuron.split()[0][1:])

                col1, col2 = st.columns(2)

                with col1:
                    # ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³æ´»æ€§åŒ–æ³¢å½¢
                    n_range = np.arange(p)
                    act = neuron_acts[:, ni]
                    act_norm = (act - act.mean()) / (act.std() + 1e-8)

                    # å¯¾å¿œã™ã‚‹ãƒ•ãƒ¼ãƒªã‚¨åŸºåº•
                    k_best = best_freqs[ni]
                    cos_basis = np.cos(2 * np.pi * k_best * n_range / p)
                    sin_basis = np.sin(2 * np.pi * k_best * n_range / p)

                    fig_wave = go.Figure()
                    fig_wave.add_trace(go.Scatter(
                        x=n_range.tolist(), y=act_norm.tolist(),
                        name=f"Neuron {ni}",
                        line=dict(color="#4CAF50", width=2)
                    ))
                    fig_wave.add_trace(go.Scatter(
                        x=n_range.tolist(), y=cos_basis.tolist(),
                        name=f"cos(2Ï€k{k_best}n/p)",
                        line=dict(color="#2196F3", width=1, dash="dash")
                    ))
                    fig_wave.add_trace(go.Scatter(
                        x=n_range.tolist(), y=sin_basis.tolist(),
                        name=f"sin(2Ï€k{k_best}n/p)",
                        line=dict(color="#F44336", width=1, dash="dash")
                    ))
                    fig_wave.update_layout(
                        title=f"Neuron {ni} vs Fourier k={k_best}",
                        xaxis_title="å…¥åŠ› n",
                        yaxis_title="æ´»æ€§åŒ–ï¼ˆæ­£è¦åŒ–ï¼‰",
                        height=350
                    )
                    st.plotly_chart(fig_wave, use_container_width=True, key="neuron_wave")

                with col2:
                    # 2Dæ´»æ€§åŒ–ãƒãƒƒãƒ—
                    if ff_out is not None:
                        n_a, n_b = len(a_vals), len(b_vals)
                        act_2d = ff_out[:, :, ni].mean(dim=1).numpy().reshape(n_a, n_b)

                        fig_2d = go.Figure(data=go.Heatmap(
                            z=act_2d,
                            x=b_vals,
                            y=a_vals,
                            colorscale="RdBu",
                            zmid=0
                        ))
                        fig_2d.update_layout(
                            title=f"Neuron {ni} æ´»æ€§åŒ–ãƒãƒƒãƒ—",
                            xaxis_title="b",
                            yaxis_title="a",
                            height=350
                        )
                        st.plotly_chart(fig_2d, use_container_width=True, key="neuron_2d")

        except Exception as e:
            st.error(f"Neuronè§£æã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            st.code(traceback.format_exc())


if __name__ == "__main__":
    main()
